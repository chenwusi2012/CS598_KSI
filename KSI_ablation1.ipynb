{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Summary"
      ],
      "metadata": {
        "id": "N0vQiW_aeU3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is to investigate the performance of the standalone document similarity learning model in the task of the medical code prediction from the clinical notes. \n",
        "\n",
        "This is the ablation study of the reproduction study of the following paper:  \n",
        "\n",
        "Tian Bai and Slobodan Vucetic. 2019. Improving medical code prediction from clinical text via incorporating online knowledge sources. In The World WideWeb Conference, WWW ’19, page 72–82, New York, NY, USA. Association for Computing Machinery."
      ],
      "metadata": {
        "id": "qNL1NawyfsaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Preparation"
      ],
      "metadata": {
        "id": "seM7lyCOn_g1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfbLDAbD-Ho9"
      },
      "source": [
        "## 2.1 Check GPU Status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0kJAKAWc_4d"
      },
      "source": [
        "This notebook requires hardware acceleration with GPU. Run the following code to make sure a GPU is running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PysjRxy7Ue3a",
        "outputId": "0cbacc6b-6a08-42aa-ae02-e09a6daa384c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 28 04:21:01 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTpL8Y_PYIVf"
      },
      "source": [
        "## 2.2 Dataset Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sraXyzOFZFDJ"
      },
      "source": [
        "In this section, the following files are loaded:\n",
        "\n",
        "* `NOTEEVENTS.csv`\n",
        "* `DIAGNOSES_ICD.csv`\n",
        "* `wikipedia_knowledge`\n",
        "* `IDlist.npy`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnmtN942Zvsl"
      },
      "source": [
        "To load `NOTEEVENTS.csv` and `DIAGNOSES_ICD.csv`, take and pass the training \"CITI Data or Specimens Only Research\" at [https://about.citiprogram.org/](https://about.citiprogram.org/), and apply for the access to the MIMIC-III Clinical Database at PhysioNet at [https://physionet.org/content/mimiciii/1.4/](https://physionet.org/content/mimiciii/1.4/). After gaining the access, download `NOTEEVENTS.csv` and `DIAGNOSES_ICD.csv` from PhysioNet, and upload these two CSV files to a created folder \"cs598_project\" in Google drive.\n",
        "  \n",
        "Mount the Google Drive to Google Colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "houR55vShhQE",
        "outputId": "f889153d-cee3-4a2d-a108-96ceaeefa3a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l95OzOa5aToH"
      },
      "source": [
        "Display the files in the \"cs598_project\" folder. Make sure `NOTEEVENTS.csv` and `DIAGNOSES_ICD.csv` are uploaded to this folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64ePN8cqnMog",
        "outputId": "482cdefc-9736-478c-908a-810e53af7c4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CAML_model  DIAGNOSES_ICD.csv  KSI_CNN_model\t  KSI_RNN_model   RNNattn_model\n",
            "CNN_model   KSI_CAML_model     KSI_RNNattn_model  NOTEEVENTS.csv  RNN_model\n"
          ]
        }
      ],
      "source": [
        "!ls drive/MyDrive/cs598_project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY0S-SeNammD"
      },
      "source": [
        "Copy `NOTEEVENTS.csv` and `DIAGNOSES_ICD.csv` from Google Drive to Google Colab Runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnsInD8unfwD"
      },
      "outputs": [],
      "source": [
        "!cp drive/MyDrive/cs598_project/DIAGNOSES_ICD.csv DIAGNOSES_ICD.csv\n",
        "!cp drive/MyDrive/cs598_project/NOTEEVENTS.csv NOTEEVENTS.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV4EY3L_a7dJ"
      },
      "source": [
        "`wikipedia_knowledge` and `IDlist.npy` can be downloaded from the GitHub Repository of the original paper ([https://github.com/tiantiantu/KSI](https://github.com/tiantiantu/KSI))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61F2nkrrNlfT",
        "outputId": "76587d62-f7c7-4c02-bc33-347b5afd9242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-28 04:22:25--  https://raw.githubusercontent.com/tiantiantu/KSI/master/wikipedia_knowledge\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5311908 (5.1M) [text/plain]\n",
            "Saving to: ‘wikipedia_knowledge’\n",
            "\n",
            "wikipedia_knowledge 100%[===================>]   5.07M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-04-28 04:22:26 (210 MB/s) - ‘wikipedia_knowledge’ saved [5311908/5311908]\n",
            "\n",
            "--2023-04-28 04:22:27--  https://github.com/tiantiantu/KSI/raw/master/IDlist.npy\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/tiantiantu/KSI/master/IDlist.npy [following]\n",
            "--2023-04-28 04:22:27--  https://raw.githubusercontent.com/tiantiantu/KSI/master/IDlist.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 316484 (309K) [application/octet-stream]\n",
            "Saving to: ‘IDlist.npy’\n",
            "\n",
            "IDlist.npy          100%[===================>] 309.07K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2023-04-28 04:22:28 (82.3 MB/s) - ‘IDlist.npy’ saved [316484/316484]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/tiantiantu/KSI/master/wikipedia_knowledge\n",
        "!wget https://github.com/tiantiantu/KSI/raw/master/IDlist.npy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Load Python Files"
      ],
      "metadata": {
        "id": "OKph7reEm6au"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`preprocessing.py`, `training.py`, and `testing.py` contains the functions for data preprocessing, training, and testing of the deep learning models. They can be downloaded from the GitHub repository of this reproduction study ([https://github.com/chenwusi2012/CS598_KSI]())."
      ],
      "metadata": {
        "id": "EDStu2ARKHhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/chenwusi2012/CS598_KSI/main/preprocessing.py\n",
        "!wget https://raw.githubusercontent.com/chenwusi2012/CS598_KSI/main/training.py\n",
        "!wget https://raw.githubusercontent.com/chenwusi2012/CS598_KSI/main/testing.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5BsxpoXnTlX",
        "outputId": "00f73a58-90de-4e8f-b4a8-026c0f569aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-28 04:22:28--  https://raw.githubusercontent.com/chenwusi2012/CS598_KSI/main/preprocessing.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1717 (1.7K) [text/plain]\n",
            "Saving to: ‘preprocessing.py’\n",
            "\n",
            "preprocessing.py    100%[===================>]   1.68K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-28 04:22:28 (35.8 MB/s) - ‘preprocessing.py’ saved [1717/1717]\n",
            "\n",
            "--2023-04-28 04:22:28--  https://raw.githubusercontent.com/chenwusi2012/CS598_KSI/main/training.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4678 (4.6K) [text/plain]\n",
            "Saving to: ‘training.py’\n",
            "\n",
            "training.py         100%[===================>]   4.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-28 04:22:28 (74.9 MB/s) - ‘training.py’ saved [4678/4678]\n",
            "\n",
            "--2023-04-28 04:22:28--  https://raw.githubusercontent.com/chenwusi2012/CS598_KSI/main/testing.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5172 (5.1K) [text/plain]\n",
            "Saving to: ‘testing.py’\n",
            "\n",
            "testing.py          100%[===================>]   5.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-28 04:22:29 (71.5 MB/s) - ‘testing.py’ saved [5172/5172]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Check Loaded Files"
      ],
      "metadata": {
        "id": "LOvDPBiz2L6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if the required files for this notebook have been loaded to the directory."
      ],
      "metadata": {
        "id": "15-MOjAp4MsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "assert os.path.exists('NOTEEVENTS.csv'), \"NOTEEVENTS.csv is not in the directory\"\n",
        "assert os.path.exists('DIAGNOSES_ICD.csv'), \"DIAGNOSES_ICD.csv is not in the directory\"\n",
        "assert os.path.exists('wikipedia_knowledge'), \"wikipedia_knowledge is not in the directory\"\n",
        "assert os.path.exists('IDlist.npy'), \"IDlist.npy is not in the directory\"\n",
        "assert os.path.exists('preprocessing.py'), \"preprocessing.py is not in the directory\"\n",
        "assert os.path.exists('training.py'), \"training.py is not in the directory\"\n",
        "assert os.path.exists('testing.py'), \"testing.py is not in the directory\""
      ],
      "metadata": {
        "id": "eDKtn0x-2UnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSFxY46aet2F"
      },
      "source": [
        "## 2.5 Running Time Tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EebpslhDelbO"
      },
      "source": [
        "Import timeit and datetime to track the running time of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv1HPfLA60Nc"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "import datetime\n",
        "total_start = timeit.default_timer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Data Pre-processing"
      ],
      "metadata": {
        "id": "hs7LLN-goPiw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlWdp-4V-aqS"
      },
      "source": [
        "## 3.1 Data Pre-processing 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6t9c0y4ebaW"
      },
      "source": [
        "Install `stop-words` to filter out stop words in the clinical notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHBorULhpNXR",
        "outputId": "9ca7ae16-f605-4899-eace-bb0b3c49e3b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stop-words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32910 sha256=ca6544ce4bdfa33863d9e920c6462ca7f3fca13ca810882851fcc815ca81efc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/1a/23/f12552a50cb09bcc1694a5ebb6c2cd5f2a0311de2b8c3d9a89\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ]
        }
      ],
      "source": [
        "!pip install stop-words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the needed Python packages for this section."
      ],
      "metadata": {
        "id": "wKtUOzKfhFT5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhl6WfZAoeUD"
      },
      "outputs": [],
      "source": [
        "import codecs\n",
        "from collections import defaultdict\n",
        "import csv\n",
        "import string\n",
        "from stop_words import get_stop_words    # download stop words package from https://pypi.org/project/stop-words/\n",
        "import numpy as np\n",
        "import datetime\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record the start timestamp of this section to track the total running time of this section."
      ],
      "metadata": {
        "id": "RZv1K2xzgu83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjxnwUaaGg1i"
      },
      "outputs": [],
      "source": [
        "start = timeit.default_timer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kk0iqHOBo4S"
      },
      "source": [
        "Create a dictionary from `NOTEEVENTS.csv`. The key is `HADM_ID` (ID of a visit), and the value is clinical note.  \n",
        "For clinical note, replace line change with whitespace, remove punctuation, and lowercase all letters.  \n",
        "From paper: \"During preprocessing we lowercased all\n",
        "tokens and removed punctuations, stop words, words containing\n",
        "only digits, and words whose frequency is less than 10\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LVfixu8AVr2"
      },
      "outputs": [],
      "source": [
        "stop_words = get_stop_words('english')\n",
        "\n",
        "admidic=defaultdict(list)\n",
        "num_of_notes=0\n",
        "\n",
        "with open('NOTEEVENTS.csv', 'r') as csvfile:\n",
        "  spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
        "  for row in spamreader: # Iterate all entries in NOTEEVETS\n",
        "    if row[6]=='Discharge summary': # Check if the category is discharge summary\n",
        "      # identify patients through subject_id\n",
        "      # append text to the list of text for a HADM_ID (visit) \n",
        "      # lower case all words, and remove punctuation\n",
        "      admidic[row[2]].append(row[-1].replace('\\n',' ').translate(str.maketrans('','',string.punctuation)).lower())\n",
        "      num_of_notes = num_of_notes+1 # count number of discharge summary notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-cDy3beDLjk"
      },
      "source": [
        "Calculate the word ocurrence (including stop words) in `NOTEEVENTS.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHvu1UZbDc_Z"
      },
      "outputs": [],
      "source": [
        "u=defaultdict(int) # The default count for each word is 0\n",
        "for i in admidic: # for each visit\n",
        "  for jj in admidic[i]: # for each saved note\n",
        "    line=jj.strip('\\n').split() # split into a list of words\n",
        "    for j in line: # Iterate each word\n",
        "      u[j]=u[j]+1 # count the number of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9hfrS-9ENB6"
      },
      "source": [
        "Print the number of words (vocabulary) in `NOTEEVENTS.csv`.  \n",
        "Print the ocurrence of the word \"consistent\" in `NOTEEVENTS.csv`.  \n",
        "Check if the stop word \"the\" in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvhIGKugD0rb",
        "outputId": "b8d69c4e-569a-4362-f739-8a37f60706a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in NOTEEVENTS.csv = 529818\n",
            "35831\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of words in NOTEEVENTS.csv = {len(u)}\")\n",
        "print(u[\"consistent\"])\n",
        "print(\"the\" in u)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OiaRFg8E3Ep"
      },
      "source": [
        "Remove the stopwords.  \n",
        "Remove the words whose number of occurence is less than 10.  \n",
        "From paper: \"During preprocessing we lowercased all\n",
        "tokens and removed punctuations, stop words, words containing\n",
        "only digits, and words whose frequency is less than 10\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhdazHeWFFBg"
      },
      "outputs": [],
      "source": [
        "u2=defaultdict(int) # Create a new dict to filter out some words\n",
        "for i in u: # iterate each word\n",
        "  if i.isdigit()==False: # Make sure not a number\n",
        "    if u[i]>10: # Make sure the word occurence is higher than 10\n",
        "      if i not in stop_words: # Make sure not stop words\n",
        "        u2[i]=u[i]\n",
        "num_of_words_in_notes = len(u2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3WioX6eFW3C"
      },
      "source": [
        "Print the number of words (vocabulary) in `NOTEEVENTS.csv` AFTER the removal of stopwords (From paper: \"The final\n",
        "word vocabulary contains 47,965 unique words.\").  \n",
        "Check if the stop word \"the\" in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTGa6IooFTBV",
        "outputId": "9d7817df-3f96-4a37-ea11-eaae8427887a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in NOTEEVENTS.csv = 47964\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of words in NOTEEVENTS.csv = {num_of_words_in_notes}\")\n",
        "print(\"the\" in u2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIe0nf07Ij7S"
      },
      "source": [
        "Create a dictionary for `DIAGNOSES_ICD.csv`. The key is `HADM_ID`, and the value if a list of ICD-9 codes for `HADM_ID`.  \n",
        "Add a prefix \"d_\" to the ICD-9 codes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nkbht_bfHum5"
      },
      "outputs": [],
      "source": [
        "u=[]   \n",
        "\n",
        "file1=codecs.open('DIAGNOSES_ICD.csv','r')\n",
        "ad2c=defaultdict(list)\n",
        "line=file1.readline() # Skip the 1st line\n",
        "line=file1.readline() # Read the 2nd line\n",
        "\n",
        "while line:\n",
        "  line=line.strip().split(',') # Split a row into a list\n",
        "\n",
        "  if line[4][1:-1]!='': # If ICD9_CODE column is not empty\n",
        "    ad2c[line[2]].append(\"d_\"+line[4][1:-1]) # Append the code to list of codes for a HADM_ID\n",
        "  \n",
        "  line=file1.readline() # Read the next line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s98bQUxEJGjl"
      },
      "source": [
        "Print a sample key-value pair (ICD-9 codes for visit 172335)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TygSO_osJPFP",
        "outputId": "19a44781-f7ff-4448-8ce0-89d6f2763232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['d_40301', 'd_486', 'd_58281', 'd_5855', 'd_4254', 'd_2762', 'd_7100', 'd_2767', 'd_7243', 'd_45829', 'd_2875', 'd_28521', 'd_28529', 'd_27541']\n",
            "14\n"
          ]
        }
      ],
      "source": [
        "print(ad2c[\"172335\"])\n",
        "print(len(ad2c[\"172335\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUuWJPrmKRhv"
      },
      "source": [
        "Calculate the code ocurrence in `DIAGNOSES_ICD.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFsluq1iKNpB"
      },
      "outputs": [],
      "source": [
        "codeu=defaultdict(int)\n",
        "for i in ad2c:\n",
        "  for j in ad2c[i]:\n",
        "    codeu[j]=codeu[j]+1 # counter the occurence of codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GybgwUEBK2DI"
      },
      "source": [
        "Print the number of unique ICD-9 codes (original codes) in `DIAGNOSES_ICD.csv`.  \n",
        "Print the number of occurence for a code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4K06NaIKkdn",
        "outputId": "bd4cb09d-754d-4cc1-cfc8-eace0ca05df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of codes in DIAGNOSES_ICD.csv = 6984\n",
            "4839\n"
          ]
        }
      ],
      "source": [
        "print(f\"number of codes in DIAGNOSES_ICD.csv = {len(codeu)}\")\n",
        "print(codeu[\"d_486\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO0Dyqtc_aaa"
      },
      "source": [
        "Group ICD-9 codes in `DIAGNOSES_ICD.csv` by the first 3 letters (From paper: \"We extracted all\n",
        "listed ICD-9 diagnosis codes for each visit and grouped them by\n",
        "their first three digits\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j6BW_VA9M7j"
      },
      "outputs": [],
      "source": [
        "ad2c2 = defaultdict(list)\n",
        "for hadm_id in ad2c:\n",
        "  for code in ad2c[hadm_id]:\n",
        "    if code[0:5] not in ad2c2[hadm_id]:\n",
        "      ad2c2[hadm_id].append(code[0:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCTpz739_mn6"
      },
      "source": [
        "Print a sample key-value pair (same as the one before ICD-9 code grouping)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cScwSxfM_GCb",
        "outputId": "3558b3df-394a-4169-ceec-b535673e06d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['d_403', 'd_486', 'd_582', 'd_585', 'd_425', 'd_276', 'd_710', 'd_724', 'd_458', 'd_287', 'd_285', 'd_275']\n",
            "12\n"
          ]
        }
      ],
      "source": [
        "print(ad2c2[\"172335\"])\n",
        "print(len(ad2c2[\"172335\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGWvVPCw_xrn"
      },
      "source": [
        "Calculate the code ocurrence in DIAGNOSES_ICD.csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR1NS10fQs6z"
      },
      "outputs": [],
      "source": [
        "codeu2=defaultdict(int)\n",
        "for hadm_id in ad2c2:\n",
        "  for code in ad2c2[hadm_id]:\n",
        "    codeu2[code]=codeu2[code]+1 # counter the occurence of codes\n",
        "num_of_codes_in_notes = len(codeu2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa_vMKj0AEOb"
      },
      "source": [
        "Print the number of unique ICD-9 codes (after grouping) in `DIAGNOSES_ICD.csv` (From paper: \"The code vocabulary contains 942 codes.\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80bKVTDc_Q5W",
        "outputId": "801c5e25-3580-459c-9015-f4335292dfb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of codes after grouping = 942\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of codes after grouping = {num_of_codes_in_notes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qCjfDnUNifD"
      },
      "source": [
        "Iterate `HADM_ID` in `IDlist.npy`, and combine the code data (from `DIAGNOSES_ICD.csv`) and note data (from `NOTEEVENTS.csv`) into a single file `combined_dataset`.  \n",
        "`combined_dataset`: A dataset contains the clinical notes of hospital visits and corresponding diagnosis (ICD-9 codes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31lmsgy23wPv"
      },
      "outputs": [],
      "source": [
        "fileo=codecs.open(\"combined_dataset\",'w')\n",
        "\n",
        "num_of_aggregated_notes = 0\n",
        "lower_limit_freq = 0\n",
        "upper_limit_freq = 10000000\n",
        "\n",
        "IDlist=np.load('IDlist.npy',encoding='bytes').astype(str) # a list of HADM_ID\n",
        "for hadm_id in IDlist:\n",
        "  if ad2c2[hadm_id]!=[]: # If HADM_ID exists in ad2c\n",
        "    add_to_set = False\n",
        "    for code in ad2c2[hadm_id]:\n",
        "      if codeu2[code] >= lower_limit_freq and codeu2[code] <= upper_limit_freq:\n",
        "        add_to_set = True\n",
        "    if add_to_set:\n",
        "      fileo.write('start! '+i+'\\n')\n",
        "      fileo.write('codes: ')\n",
        "      tempc=[]\n",
        "      for code in ad2c2[hadm_id]: # for each code\n",
        "        if codeu2[code] >= lower_limit_freq and codeu2[code] <= upper_limit_freq: # if code occurence greater than threshold\n",
        "          if code not in tempc:\n",
        "            tempc.append(code) # save d_ and first 3 digits of ICD-9 code\n",
        "      \n",
        "      for code in tempc:\n",
        "        fileo.write(code+\" \") # write code to combined dataset\n",
        "      fileo.write('\\n')\n",
        "      fileo.write('notes:\\n') # write note\n",
        "      for line in admidic[hadm_id]: # iterate each line    \n",
        "        thisline=line.strip('\\n').split() \n",
        "        for j in thisline: # iterate each word\n",
        "          if u2[j]!=0: # if this word is a qualified word\n",
        "            fileo.write(j+\" \") # write this word\n",
        "          fileo.write('\\n')\n",
        "      fileo.write('end!\\n')\n",
        "      num_of_aggregated_notes = num_of_aggregated_notes + 1\n",
        "fileo.close()\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olb3AGDhEI-x"
      },
      "source": [
        "Print the number of note-code pairs added to the dataset (From paper:\"The number of aggregated discharge summary notes is 52,722..\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhzMBfP7D_qe",
        "outputId": "fb59d874-6c63-4481-cc43-56fc42cc6b66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of notes written to combined dataset = 52722\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of notes written to combined dataset = {num_of_aggregated_notes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the total running time of this section."
      ],
      "metadata": {
        "id": "ewGvvJBtg2aH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZDh7aDeD_fY",
        "outputId": "19d19b34-da48-4ee1-e899-c8b093efe54c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time duration: 0h 01m 38s\n"
          ]
        }
      ],
      "source": [
        "stop = timeit.default_timer()\n",
        "duration = str(datetime.timedelta(seconds=round(stop-start)))\n",
        "duration = duration.split(\":\")\n",
        "print(f'Time duration: {duration[0]}h {duration[1]}m {duration[2]}s') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COK-Hrv5-knl"
      },
      "source": [
        "## 3.2 Data Pre-processing 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the needed Python packages for this section."
      ],
      "metadata": {
        "id": "_5jp7zUZhIcd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yrbstc1758MT"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record the start timestamp of this section to track the total running time of this section."
      ],
      "metadata": {
        "id": "4yRFj1UOgxBj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLfX0hlBGsBK"
      },
      "outputs": [],
      "source": [
        "start = timeit.default_timer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f2ORuVJIlnU"
      },
      "source": [
        "Build a vocabulary for Wiki documents. The key is a word, and the value is 1 if the word exists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5kSmQc3ImLq"
      },
      "outputs": [],
      "source": [
        "wikivocab={}\n",
        "file1=codecs.open(\"wikipedia_knowledge\",'r','utf-8')\n",
        "line=file1.readline()\n",
        "while line:\n",
        "  if line[0:3]!='XXX': # if this line is not start or end of doc\n",
        "    line=line.strip('\\n')\n",
        "    line=line.split()\n",
        "    for i in line: # iterate each word\n",
        "      wikivocab[i.lower()]=1 # if a word exists in doc, set to 1\n",
        "  line=file1.readline()\n",
        "num_of_words_in_wiki = len(wikivocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxyybgFLJgNK"
      },
      "source": [
        "Print the size of the vocabulary for Wiki documents (From paper: \"The size\n",
        "of the word vocabulary of Wikipedia documents is 60,968.\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4tCwHxXJDwi",
        "outputId": "e6c84567-bb05-4b60-e2be-eb274d00f1e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words in Wiki documents = 60968\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of unique words in Wiki documents = {num_of_words_in_wiki}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOo0A3-9KEAC"
      },
      "source": [
        "Build a vocabulary for `NOTEEVENTS.csv` (after word processing). The key is a word, and the value is 1 if the word exists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "In7y-or4KWE8"
      },
      "outputs": [],
      "source": [
        "notesvocab={}\n",
        "filec=codecs.open(\"combined_dataset\",'r','utf-8')\n",
        "\n",
        "line=filec.readline()\n",
        "\n",
        "while line:\n",
        "  line=line.strip('\\n')\n",
        "  line=line.split()\n",
        "  \n",
        "  if line[0]=='codes:':\n",
        "    line=filec.readline()\n",
        "    line=line.strip('\\n')\n",
        "    line=line.split()\n",
        "    \n",
        "    if line[0]=='notes:': \n",
        "      line=filec.readline()\n",
        "      while line!='end!\\n':\n",
        "        line=line.strip('\\n')\n",
        "        line=line.split()\n",
        "        for word in line:\n",
        "          notesvocab[word]=1\n",
        "        line=filec.readline()            \n",
        "  line=filec.readline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPXbUzq6LcRR"
      },
      "source": [
        "Print the size of vocabulary for `NOTEEVENTS.csv` after word processing (From paper: \"The final word vocabulary contains 47,965 unique words.\").  \n",
        "Print a sample key-value pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtN8IgIZK_pY",
        "outputId": "9f5fdfd8-29da-4c6c-e514-7ffddfd4aea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47964\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "print(len(notesvocab))\n",
        "print(notesvocab[\"consistent\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3VGW7dkL_PE"
      },
      "source": [
        "Get an intersection of the vocabulary for wiki documents and the one for `NOTEVENTS.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9JMMHhiMITq"
      },
      "outputs": [],
      "source": [
        "a1=set(notesvocab)\n",
        "a2=set(wikivocab)\n",
        "a3=a1.intersection(a2) # get the intersection\n",
        "num_of_words_in_both = len(a3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ladA4oybMY73"
      },
      "source": [
        "Print number of unique words in the intersection (From paper: \"The size of the word vocabulary of Wikipedia documents is 60,968, out of which only 12,173 are also in the word vocabulary of MIMIC-III clinical notes.\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcJK3dukMeYS",
        "outputId": "22606027-ef9c-42cb-a806-dc7063f82303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12173\n"
          ]
        }
      ],
      "source": [
        "print(num_of_words_in_both)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYZxImH0NdDf"
      },
      "source": [
        "Create a list of lists. Each element list is a list of intersected words for one Wiki document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHj2uu7SNaQn"
      },
      "outputs": [],
      "source": [
        "wikidocuments=[] # a list of lists, each element is a list of intersected and filtered words for one doc\n",
        "file2=codecs.open(\"wikipedia_knowledge\",'r','utf-8')\n",
        "line=file2.readline() \n",
        "while line:\n",
        "  if line[0:4]=='XXXd': # Check if it is a start of a wiki doc\n",
        "    tempf=[]\n",
        "    line=file2.readline() # read the next line\n",
        "    while line[0:4]!='XXXe': # keep reading until the end of that doc\n",
        "      line=line.strip('\\n')\n",
        "      words=line.split()\n",
        "      for word in words:\n",
        "        if word.lower() in a3: # if this word also appears in note\n",
        "          tempf.append(word.lower()) # add this word to the list for this doc\n",
        "      line=file2.readline()\n",
        "    wikidocuments.append(tempf) # add word list of doc to list of docs \n",
        "  line=file2.readline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcK34TJLO9yM"
      },
      "source": [
        "Create a list of lists. Each element list is a list of intersected words for one clinical note."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjmPcDD6PCY1"
      },
      "outputs": [],
      "source": [
        "notesdocuments=[] # a list of lists, each element is a list of intersected and filtered words for one note\n",
        "file3=codecs.open(\"combined_dataset\",'r','utf-8')\n",
        "line=file3.readline()\n",
        "while line:\n",
        "  line=line.strip('\\n')\n",
        "  line=line.split()\n",
        "  if line[0]=='codes:': # if this line is for code\n",
        "    line=file3.readline() # skip this line\n",
        "    line=line.strip('\\n')\n",
        "    line=line.split()\n",
        "    if line[0]=='notes:': # if this line is for note\n",
        "      tempf=[]\n",
        "      line=file3.readline()\n",
        "      while line!='end!\\n': # keep reading until the end of the note\n",
        "        line=line.strip('\\n')\n",
        "        line=line.split()\n",
        "        for word in line:\n",
        "          if word in a3:\n",
        "            tempf.append(word)     \n",
        "        line=file3.readline()      \n",
        "      notesdocuments.append(tempf)\n",
        "  line=file3.readline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgP1wKEWSVV2"
      },
      "source": [
        "Set the sequence of words in the vocabulary matrix. Key is a word, and the value is the sequence/order in the vocabulary matrix.  \n",
        "This is a preparation for building the matrices of the intersected words for Wiki documents and clinical notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGwAnUihS5sY"
      },
      "outputs": [],
      "source": [
        "notesvocab={}\n",
        "for i in notesdocuments: # for each element (is a list) in list\n",
        "  for j in i: # for each word\n",
        "    if j.lower() not in notesvocab: # if a word is not in dict\n",
        "      # # set value of this word equal to current element (order of the token in matrix)\n",
        "      notesvocab[j.lower()]=len(notesvocab) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RKZthpkV8g1"
      },
      "source": [
        "Create a list of string for Wiki document, and each element is a string for a Wiki document (including intersected words).\n",
        "This is a preparation for building the matrices of the intersected words for Wiki documents and clinical notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWcFW-QEV63H"
      },
      "outputs": [],
      "source": [
        "wikidata=[] # each element is a string, each string contains words for a wiki doc\n",
        "for i in wikidocuments:\n",
        "  temp=''\n",
        "  for j in i:\n",
        "    temp=temp+j+\" \"\n",
        "  wikidata.append(temp)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te_XDGn_VFlV"
      },
      "source": [
        "Create a list of string for clinical notes, and each element is a string for a note (including intersected words).  \n",
        "This is a preparation for building the matrices of the intersected words for Wiki documents and clinical notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsxeKIhJVEI8"
      },
      "outputs": [],
      "source": [
        "notedata=[] # each element is a string, each string contains words for a note\n",
        "for i in notesdocuments: # for each element (list) in list\n",
        "  temp=''\n",
        "  for j in i: # for each word\n",
        "    temp=temp+j+\" \" # create a string, words for a note separated by a space\n",
        "  notedata.append(temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-zZsHsfZETc"
      },
      "source": [
        "Create 2 word matrices (intersected words). One is for Wiki documents, and the other is for clinical notes.  \n",
        "`notevec`: A matrix of intersected words for clinical notes.  \n",
        "`wikivec`: A matrix of intersected words for Wiki documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBfUhADjZVha"
      },
      "outputs": [],
      "source": [
        "# create a matrix of token counts\n",
        "vect = CountVectorizer(min_df=1,vocabulary=notesvocab,binary=True)\n",
        "# transfer list of string to matrix, if a word exists in a string, set value to 1\n",
        "binaryn = vect.fit_transform(notedata)\n",
        "binaryn=binaryn.A # Return self as an ndarray object.\n",
        "binaryn=np.array(binaryn,dtype=float)\n",
        "\n",
        "vect2 = CountVectorizer(min_df=1,vocabulary=notesvocab,binary=True)\n",
        "binaryk = vect2.fit_transform(wikidata)\n",
        "binaryk=binaryk.A\n",
        "binaryk=np.array(binaryk,dtype=float)\n",
        "notevec = binaryn\n",
        "wikivec = binaryk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDe_Hdt2Zy7s"
      },
      "source": [
        "Print the shape of the created matrices.  \n",
        "For the matrix for clinical notes, the size of 1st dimension is the number of notes, and the size of the 2nd dimension is the number of intersected words.  \n",
        "For the matrix for Wiki documents, the size of 1st dimension is the number of Wiki documents, and the size of the 2nd dimension is the number of intersected words.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alNBP-KwZ3L7",
        "outputId": "627e328c-efa5-463e-808b-9cccbe056a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the matrix for clinical notes (notevec) = (52722, 12173)\n",
            "The shape of the matrix for wiki docs (wikivec) = (325, 12173)\n"
          ]
        }
      ],
      "source": [
        "print(f\"The shape of the matrix for clinical notes (notevec) = {binaryn.shape}\")\n",
        "print(f\"The shape of the matrix for wiki docs (wikivec) = {binaryk.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the total running time of this section."
      ],
      "metadata": {
        "id": "-Ku4DbKig4gD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4Bc7NWJ6TuA",
        "outputId": "aba892d1-3a03-4299-9bb8-f2e588aef1fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time duration: 0h 04m 03s\n"
          ]
        }
      ],
      "source": [
        "stop = timeit.default_timer()\n",
        "duration = str(datetime.timedelta(seconds=round(stop-start)))\n",
        "duration = duration.split(\":\")\n",
        "print(f'Time duration: {duration[0]}h {duration[1]}m {duration[2]}s')   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA3PKA3o-zIW"
      },
      "source": [
        "## 3.3 Data Pre-processing 3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the needed Python packages for this section."
      ],
      "metadata": {
        "id": "6pJLOFLqhJTZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmglWv6s9Jhc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record the start timestamp of this section to track the total running time of this section."
      ],
      "metadata": {
        "id": "rZAhvfuJgyVp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqMqsHWScDco"
      },
      "outputs": [],
      "source": [
        "start = timeit.default_timer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dMkHxzFeEGD"
      },
      "source": [
        "Create 2 dictionaries for the ICD-9 codes for Wiki documents.  \n",
        "For the 1st dictionary, the key is a ICD-9 code which exists in Wiki documents, and the value is 1.\n",
        "For the 2nd dictionary, the key is a ICD-9 code which exists in Wiki documents, and the value is the list which contain the sequence number of Wiki documents for this ICD-9 code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNU5O0HNcLOB"
      },
      "outputs": [],
      "source": [
        "wikivoc={}\n",
        "codewiki=defaultdict(list)\n",
        "\n",
        "file2=codecs.open(\"wikipedia_knowledge\",'r','utf-8')\n",
        "line=file2.readline()\n",
        "count=0\n",
        "while line:\n",
        "  if line[0:4]=='XXXd': # read the start of a wiki doc\n",
        "    line=line.strip('\\n')\n",
        "    codes=line.split()\n",
        "    for code in codes:\n",
        "      if code[0:2]=='d_': # if it is a icd code\n",
        "        codewiki[code].append(count) # save the index of wiki doc to list for code\n",
        "        wikivoc[code]=1 # set value of code to 1\n",
        "    count=count+1\n",
        "  line=file2.readline()\n",
        "  num_of_codes_in_wiki = len(wikivoc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXmyJz6chflJ"
      },
      "source": [
        "Each of the following 4 ICD-9 codes appears in 2 Wiki documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZR9TGFAhDM2",
        "outputId": "d007eb23-ae80-4823-ae24-458cf2156fee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[47, 214]\n",
            "[106, 125]\n",
            "[149, 250]\n",
            "[219, 221]\n"
          ]
        }
      ],
      "source": [
        "print(codewiki['d_072'])\n",
        "print(codewiki['d_698'])\n",
        "print(codewiki['d_305'])\n",
        "print(codewiki['d_386'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXlRQZ4khr9V"
      },
      "source": [
        "For training purpose, each Wiki document can have more than one ICD-9 code, but each ICD-9 code can appear in only one Wiki document.  \n",
        "Correct the 4 ICD-9 codes above, and for each of these 4 codes, down-select one Wiki document.  \n",
        "`wikivoc`: A matrix of ICD-9 codes which appear in Wiki documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFSJFFcriWRC"
      },
      "outputs": [],
      "source": [
        "codewiki['d_072']=[214]\n",
        "codewiki['d_698']=[125]\n",
        "codewiki['d_305']=[250]\n",
        "codewiki['d_386']=[219]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRJq3pVJOZHO"
      },
      "source": [
        "Prepare feature and label for the deep learning model.  \n",
        "Feature: A list of string. Each string is one clinical note.  \n",
        "Label: A list of string. Each string is the ICD-9 codes for one clinical note."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EM3pmjJZOTEX"
      },
      "outputs": [],
      "source": [
        "filec=codecs.open(\"combined_dataset\",'r','utf-8')\n",
        "\n",
        "line=filec.readline()\n",
        "\n",
        "feature=[]\n",
        "label=[]\n",
        "\n",
        "while line:\n",
        "  line=line.strip('\\n')\n",
        "  line=line.split()\n",
        "  \n",
        "  if line[0]=='codes:':\n",
        "    temp=line[1:] # read the codes of that node\n",
        "    label.append(temp) # add the code to list for label\n",
        "    line=filec.readline()\n",
        "    line=line.strip('\\n')\n",
        "    line=line.split()\n",
        "    if line[0]=='notes:':\n",
        "      tempf=[]\n",
        "      line=filec.readline()\n",
        "      \n",
        "      while line!='end!\\n': # read the notes until end\n",
        "        line=line.strip('\\n')\n",
        "        line=line.split()\n",
        "        tempf=tempf+line\n",
        "        line=filec.readline()\n",
        "      feature.append(tempf) # add list of words to list of feature\n",
        "  line=filec.readline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4la9dYtOTPLz"
      },
      "source": [
        "Create the sequence for label (ICD-9 codes). The key is a ICD-9 code, and the value is the sequence of a ICD-9 code in the code vector later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrzF4EYGTksY"
      },
      "outputs": [],
      "source": [
        "prevoc={}\n",
        "for i in label:\n",
        "  for j in i:\n",
        "    if j not in prevoc:\n",
        "      prevoc[j] = len(prevoc) # set up the order of codes (for vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skouqwX8TtHz"
      },
      "source": [
        "Print a sample key-value pairs (refer to `label[0]`).  \n",
        "Print the number of key-value pairs (codes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8zU8E3uTwvn",
        "outputId": "f0e01c41-2239-4175-a39a-2eae25f223ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "941\n"
          ]
        }
      ],
      "source": [
        "print(prevoc[\"d_486\"])\n",
        "print(prevoc[\"d_518\"])\n",
        "print(prevoc[\"d_511\"])\n",
        "print(len(prevoc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvRlVNfjVgon"
      },
      "source": [
        "Create mapping between ICD-9 codes and the index in the code vector by 2 dictionaries.  \n",
        "**This mapping is for all codes found in the combined dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxSZbDm9Vq9N"
      },
      "outputs": [],
      "source": [
        "label_to_ix = {}\n",
        "ix_to_label = {}\n",
        "\n",
        "# create a mapping between code and index\n",
        "for codes in label:\n",
        "  for code in codes:\n",
        "    if code not in label_to_ix:\n",
        "      label_to_ix[code]=len(label_to_ix)\n",
        "      ix_to_label[label_to_ix[code]]=code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz3jD8rBWDYa"
      },
      "source": [
        "Print sample key-value pairs.  \n",
        "Print the number of ICD-9 codes found in combined dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk3ABC2ZWGfM",
        "outputId": "5e0a0400-81d1-4549-d071-01cb9d91d81b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "d_486\n",
            "Total number of codes = 941\n"
          ]
        }
      ],
      "source": [
        "print(label_to_ix[\"d_486\"])\n",
        "print(ix_to_label[0])\n",
        "print(f\"Total number of codes = {len(label_to_ix)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4JxLlXIfI8_"
      },
      "source": [
        "Create a word vector (intersected words) for each of the ICD-9 codes found in combined_dataset.\n",
        "*   If a ICD-9 code can be found in Wiki documents: label index -> ICD-9 code -> sequence/index of Wiki document -> vector of intersected words of Wikidocument (1 x number of intersected words).\n",
        "*   If ICD-9 code cannot be found in Wiki document: zero vector in shape of (1 x number of intersected words).\n",
        "Create a mapping between ICD-9 code index in label and corresponding "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m7qfTVDeap9"
      },
      "outputs": [],
      "source": [
        "tempwikivec=[]\n",
        "\n",
        "for i in range(0,len(ix_to_label)):\n",
        "  if ix_to_label[i] in wikivoc: # if a code in note can be found in wiki docs\n",
        "    temp=wikivec[codewiki[ix_to_label[i]][0]] # save wiki doc index to temp\n",
        "    tempwikivec.append(temp)\n",
        "  else:\n",
        "    tempwikivec.append([0.0]*wikivec.shape[1])\n",
        "wikivec=np.array(tempwikivec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWwAFL04ktBd"
      },
      "source": [
        "Create dataset. The dataset contains 3 parts:\n",
        "*   Feature: a list of lists, and each element is a list of words (strings) for one clinical note.\n",
        "*   Notevec: a list of vectors, and each element is a vector of intersected words for one clinical note.\n",
        "*   Label: a list of lists, and each element is a list of ICD-codes for one clinical note."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9OSJf1Nec4t"
      },
      "outputs": [],
      "source": [
        "data=[]\n",
        "for i in range(0,len(feature)):\n",
        "  # save feature (list of words for note), note matrix and label (code) as a tuple\n",
        "  data.append((feature[i], notevec[i], label[i]))\n",
        "    \n",
        "data=np.array(data, dtype=object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xbg7p7InnXq"
      },
      "source": [
        "Create mapping between ICD-9 codes and the index in the code vector by 2 dictionaries.  \n",
        "**Different from previous `label_to_ix` and `ix_to_label`, this mapping is for ICD-9 codes found in Wiki documents only.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiEMkZjkelOm"
      },
      "outputs": [],
      "source": [
        "label_to_ix = {}\n",
        "ix_to_label = {}\n",
        "\n",
        "for doc, note, codes in data:\n",
        "  for code in codes:\n",
        "    if code not in label_to_ix:\n",
        "      if code in wikivoc:\n",
        "        label_to_ix[code]=len(label_to_ix)\n",
        "        ix_to_label[label_to_ix[code]]=code\n",
        "\n",
        "num_of_codes_in_both = len(label_to_ix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRTLBW7dqUgf"
      },
      "source": [
        "Print sample key-value pairs.  \n",
        "Print the number of ICD-9 codes which **exists in both clinical notes and Wiki documents** (From paper: \"Of those codes, we selected a subset of 344 codes for which we found the corresponding Wikipedia document and used those codes in our experiments.\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUc2UUh-nMqZ",
        "outputId": "031ae64a-6f53-4f65-c6cf-5c97ad4f9734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "d_486\n",
            "Total number of codes = 344\n"
          ]
        }
      ],
      "source": [
        "print(label_to_ix[\"d_486\"])\n",
        "print(ix_to_label[0])\n",
        "print(f\"Total number of codes = {num_of_codes_in_both}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x2BllzNvJnH"
      },
      "source": [
        "Split training data, validation data, and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90BcKLLXerYC"
      },
      "outputs": [],
      "source": [
        "training_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "training_data, val_data = train_test_split(training_data, test_size=0.125, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYfRRu_pB2K7"
      },
      "source": [
        "Create index for words in clinical notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNJKARBVeuI4"
      },
      "outputs": [],
      "source": [
        "word_to_ix = {}\n",
        "ix_to_word={}\n",
        "ix_to_word[0]='OUT'\n",
        "\n",
        "for doc, note, codes in training_data:\n",
        "  for word in doc:\n",
        "    if word not in word_to_ix:\n",
        "      word_to_ix[word] = len(word_to_ix)+1\n",
        "      ix_to_word[word_to_ix[word]]=word  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pl1zvOmGHBt"
      },
      "source": [
        "Print sample key-value pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiidFU4cDLtV",
        "outputId": "0bb18036-7083-4a04-e4c1-81f5f210f510"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUT\n",
            "admission\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "print(ix_to_word[0])\n",
        "print(ix_to_word[1])\n",
        "print(word_to_ix['admission'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YRAJ4AtJuem"
      },
      "source": [
        "Create a word vector (intersected words) for each of the ICD-9 codes found in **both Wiki document and clinical notes (combined dataset)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_VMHm0Eewv5"
      },
      "outputs": [],
      "source": [
        "newwikivec=[]\n",
        "for i in range(0,len(ix_to_label)):\n",
        "  newwikivec.append(wikivec[prevoc[ix_to_label[i]]])\n",
        "newwikivec=np.array(newwikivec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGp0wg9QKHSx"
      },
      "source": [
        "Print sample result.  \n",
        "Print the number of vectors in wikivec and newwikivec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWdQx4t0Hb7g",
        "outputId": "3d780db9-e5d1-4672-c580-445e8a51b53d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d_486\n",
            "0\n",
            "[1. 0. 0. ... 0. 0. 0.]\n",
            "344\n",
            "941\n"
          ]
        }
      ],
      "source": [
        "print(ix_to_label[0])\n",
        "print(prevoc[ix_to_label[0]])\n",
        "print(wikivec[prevoc[ix_to_label[0]]])\n",
        "print(len(newwikivec))\n",
        "print(len(wikivec))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the total running time of this section."
      ],
      "metadata": {
        "id": "yI8kbChFg70V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3bF8Y-_817e",
        "outputId": "2975fb18-9908-4acc-b808-cfd60c974ad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time duration: 0h 04m 11s\n"
          ]
        }
      ],
      "source": [
        "stop = timeit.default_timer()\n",
        "duration = str(datetime.timedelta(seconds=round(stop-start)))\n",
        "duration = duration.split(\":\")\n",
        "print(f'Time duration: {duration[0]}h {duration[1]}m {duration[2]}s')  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Data Pre-processing 4"
      ],
      "metadata": {
        "id": "ZaFHYR_R0NLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform data processing on the training dataset, validation dataset, and test dataset. The function `preprocessing` can be found in `preprocessing.py`."
      ],
      "metadata": {
        "id": "lJMuRf_broxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "from preprocessing import preprocessing\n",
        "\n",
        "\n",
        "wikisize=newwikivec.shape[0]\n",
        "rvocsize=newwikivec.shape[1]\n",
        "wikivec=autograd.Variable(torch.FloatTensor(newwikivec))\n",
        "\n",
        "batchsize = 32\n",
        "\n",
        "batchtraining_data=preprocessing(training_data, label_to_ix, word_to_ix, wikivoc, batchsize)\n",
        "batchtest_data=preprocessing(test_data, label_to_ix, word_to_ix, wikivoc, batchsize)\n",
        "batchval_data=preprocessing(val_data, label_to_ix, word_to_ix, wikivoc, batchsize) "
      ],
      "metadata": {
        "id": "-UGuOeuZ0Sdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNEqr0QqvXan"
      },
      "source": [
        "# 4 Data Statistics (Overview of Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijIWWAC91OPo"
      },
      "source": [
        "The following table shows the statistics of the ***clinical notes from MIMIC-III dataset***. The values in the following table match the statistics in section 4.1 of the original paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "-U-LLj2FvY6L",
        "outputId": "ee54b174-6f77-4c62-c032-f1e634ec4093"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     Statistics  Result\n",
              "0             Number of discharge summary notes   59652\n",
              "1  Number of aggregated discharge summary notes   52722\n",
              "2    Number of words in discharge summary notes   47964\n",
              "3    Number of codes in discharge summary notes     942"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e41b566d-a3b9-4d28-ad94-5ab51888a595\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Number of discharge summary notes</td>\n",
              "      <td>59652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Number of aggregated discharge summary notes</td>\n",
              "      <td>52722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Number of words in discharge summary notes</td>\n",
              "      <td>47964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Number of codes in discharge summary notes</td>\n",
              "      <td>942</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e41b566d-a3b9-4d28-ad94-5ab51888a595')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e41b566d-a3b9-4d28-ad94-5ab51888a595 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e41b566d-a3b9-4d28-ad94-5ab51888a595');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "note_stat = []\n",
        "note_stat.append([\"Number of discharge summary notes\", num_of_notes])\n",
        "note_stat.append([\"Number of aggregated discharge summary notes\", num_of_aggregated_notes])\n",
        "note_stat.append([\"Number of words in discharge summary notes\", num_of_words_in_notes])\n",
        "note_stat.append([\"Number of codes in discharge summary notes\", num_of_codes_in_notes])\n",
        "df_note_stat = pd.DataFrame(note_stat, columns=['Statistics', 'Result'])\n",
        "df_note_stat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYswSNMq7koA"
      },
      "source": [
        "The following table shows the statistics of the ***Wikipedia articles for ICD-9 diagnosis codes***. The values in the following table match the statistics in section 4.1 of the original paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "LDlas4s810yZ",
        "outputId": "09ec6b65-fd35-4443-b191-cdb722a256f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Statistics  Result\n",
              "0        Number of words in Wiki articles   60968\n",
              "1        Number of codes in Wiki articles     389\n",
              "2  Number of words in both Wiki and notes   12173\n",
              "3  Number of codes in both Wiki and notes     344"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb59955d-b642-4a41-94d8-0b729e1ec766\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Number of words in Wiki articles</td>\n",
              "      <td>60968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Number of codes in Wiki articles</td>\n",
              "      <td>389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Number of words in both Wiki and notes</td>\n",
              "      <td>12173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Number of codes in both Wiki and notes</td>\n",
              "      <td>344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb59955d-b642-4a41-94d8-0b729e1ec766')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fb59955d-b642-4a41-94d8-0b729e1ec766 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fb59955d-b642-4a41-94d8-0b729e1ec766');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "wiki_stat = []\n",
        "num_of_words_in_wiki\n",
        "wiki_stat.append([\"Number of words in Wiki articles\", num_of_words_in_wiki])\n",
        "wiki_stat.append([\"Number of codes in Wiki articles\", num_of_codes_in_wiki])\n",
        "wiki_stat.append([\"Number of words in both Wiki and notes\", num_of_words_in_both])\n",
        "wiki_stat.append([\"Number of codes in both Wiki and notes\", num_of_codes_in_both])\n",
        "df_wiki_stat = pd.DataFrame(wiki_stat, columns=['Statistics', 'Result'])\n",
        "df_wiki_stat"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Training and Testing of Document Similarity Learning Model"
      ],
      "metadata": {
        "id": "aCxeDVhmoeI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section investigates the performance of the standalone document similarity learning model (the 2nd part/subtask in the KSI framework) in the task of ICD-9 diagnosis code prediction from the clinical notes in MIMIC-III dataset.  \n",
        "\n",
        "First, import the needed Python packages for this section."
      ],
      "metadata": {
        "id": "V0wl-PsCV1Ev"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDfshwRU9jvC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "torch.manual_seed(1)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "import copy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record the start timestamp of this section to track the total running time of this section."
      ],
      "metadata": {
        "id": "vIWCQMFqX1YM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = timeit.default_timer()"
      ],
      "metadata": {
        "id": "7wdBWP6Ilm4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the standalone document similarity learning model."
      ],
      "metadata": {
        "id": "_Jus4qx1YT6t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okDHhv5Hu6dx"
      },
      "outputs": [],
      "source": [
        "Embeddingsize = 100\n",
        "hidden_dim = 200\n",
        "\n",
        "class DSL(nn.Module):\n",
        "\n",
        "    def __init__(self, batch_size, vocab_size, tagset_size):\n",
        "        super(DSL, self).__init__()   \n",
        "        self.layer2 = nn.Linear(Embeddingsize, 1)\n",
        "        self.embedding=nn.Linear(rvocsize,Embeddingsize,bias=False)\n",
        "        self.vattention=nn.Linear(Embeddingsize,Embeddingsize)    \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, vec1, nvec, wiki, simlearning):\n",
        "        \n",
        "        nvec=nvec.view(batchsize,1,-1)\n",
        "        nvec=nvec.expand(batchsize,wiki.size()[0],-1)\n",
        "        wiki=wiki.view(1,wiki.size()[0],-1)\n",
        "        wiki=wiki.expand(nvec.size()[0],wiki.size()[1],-1)\n",
        "        new=wiki*nvec\n",
        "        new=self.embedding(new)\n",
        "        vattention=self.sigmoid(self.vattention(new))\n",
        "        new=new*vattention\n",
        "        vec3=self.layer2(new)\n",
        "        vec3=vec3.view(batchsize,-1)\n",
        "        \n",
        "        tag_scores = self.sigmoid(vec3)\n",
        "              \n",
        "        return tag_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the standalone document similarity learning model. The training will stop if the top-10 recall score does not improve on the validation dataset in the next 5 epochs. The function `trainmodel` can be found in `training.py`."
      ],
      "metadata": {
        "id": "UE94KudHYgkt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lXtJz6GunsQ",
        "outputId": "c92d8d7b-9035-4835-e735-b6f64ad79bc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max epochs = 5000\n",
            "Train model\n",
            "epoch = 0\n",
            "validation recall @ top- 10 0.5138894583423917\n",
            "Update the best model to epoch 0\n",
            "epoch = 1\n",
            "validation recall @ top- 10 0.5640364026877359\n",
            "Update the best model to epoch 1\n",
            "epoch = 2\n",
            "validation recall @ top- 10 0.5977512820990579\n",
            "Update the best model to epoch 2\n",
            "epoch = 3\n",
            "validation recall @ top- 10 0.6277291661664236\n",
            "Update the best model to epoch 3\n",
            "epoch = 4\n",
            "validation recall @ top- 10 0.6434733985778932\n",
            "Update the best model to epoch 4\n",
            "epoch = 5\n",
            "validation recall @ top- 10 0.6566980805288108\n",
            "Update the best model to epoch 5\n",
            "epoch = 6\n",
            "validation recall @ top- 10 0.662889226220894\n",
            "Update the best model to epoch 6\n",
            "epoch = 7\n",
            "validation recall @ top- 10 0.671922667512808\n",
            "Update the best model to epoch 7\n",
            "epoch = 8\n",
            "validation recall @ top- 10 0.6767062600015236\n",
            "Update the best model to epoch 8\n",
            "epoch = 9\n",
            "validation recall @ top- 10 0.6787810989132014\n",
            "Update the best model to epoch 9\n",
            "epoch = 10\n",
            "validation recall @ top- 10 0.6760485833354787\n",
            "epoch = 11\n",
            "validation recall @ top- 10 0.6762155275936145\n",
            "epoch = 12\n",
            "validation recall @ top- 10 0.6772940685847485\n",
            "epoch = 13\n",
            "validation recall @ top- 10 0.6742716529804031\n",
            "epoch = 14\n",
            "validation recall @ top- 10 0.6724404866727877\n",
            "[0.5138894583423917, 0.5640364026877359, 0.5977512820990579, 0.6277291661664236, 0.6434733985778932, 0.6566980805288108, 0.662889226220894, 0.671922667512808, 0.6767062600015236, 0.6787810989132014, 0.6760485833354787, 0.6762155275936145, 0.6772940685847485, 0.6742716529804031, 0.6724404866727877] 9\n"
          ]
        }
      ],
      "source": [
        "from training import trainmodel\n",
        "\n",
        "topk = 10\n",
        "max_epochs = 5000 # Default is 5000\n",
        "print(f\"max epochs = {max_epochs}\")\n",
        "\n",
        "model = DSL(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "model.cuda()\n",
        "\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "print(\"Train model\")\n",
        "DSLmodel= trainmodel(model, 1, topk, max_epochs, batchtraining_data, batchval_data, wikivec, loss_function, optimizer)\n",
        "torch.save(DSLmodel, 'DSL_ONLY_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the trained document similarity learning models on the test dataset. The function `testmodel` can be found in `testing.py`."
      ],
      "metadata": {
        "id": "TeEmocpzaHc_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ3VaeGnunce",
        "outputId": "defbba11-0974-4282-d2b4-5e59cac9fad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test DSL_Only\n"
          ]
        }
      ],
      "source": [
        "from testing import testmodel\n",
        "\n",
        "\n",
        "print('Test DSL_Only')\n",
        "model1 = DSL(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "DSL_loss, DSL_recall, DSL_mac_auc, DSL_mic_auc, DSL_mac_f1, DSL_mic_f1 = testmodel(model1, DSLmodel, 0, batchtest_data, wikivec, topk)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the total running time of this section."
      ],
      "metadata": {
        "id": "m3qBdL1saS9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop = timeit.default_timer()\n",
        "duration = str(datetime.timedelta(seconds=round(stop-start)))\n",
        "duration = duration.split(\":\")\n",
        "print(f'Running time of this section: {duration[0]}h {duration[1]}m {duration[2]}s') "
      ],
      "metadata": {
        "id": "bRG3E6bMnJuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eed873c-599b-4b8d-d0dc-35dcf2590fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running time of this section: 0h 12m 50s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the performance metrics of the standalone document similarity learning model."
      ],
      "metadata": {
        "id": "ozo51c8MaYDG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "WctM9Bmjxj7q",
        "outputId": "82726621-0f0d-4a82-8f77-21db40ccb904"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Model  Macro_AUC  Micro_AUC  Macro_F1  Micro_F1  Loss  Recall@10\n",
              "0  DSL_Standalone      0.819      0.959     0.151     0.454  0.04      0.678"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c53ca69-22ca-45e7-926e-d9e7ed05fa73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Macro_AUC</th>\n",
              "      <th>Micro_AUC</th>\n",
              "      <th>Macro_F1</th>\n",
              "      <th>Micro_F1</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Recall@10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DSL_Standalone</td>\n",
              "      <td>0.819</td>\n",
              "      <td>0.959</td>\n",
              "      <td>0.151</td>\n",
              "      <td>0.454</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c53ca69-22ca-45e7-926e-d9e7ed05fa73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c53ca69-22ca-45e7-926e-d9e7ed05fa73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c53ca69-22ca-45e7-926e-d9e7ed05fa73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "result_dsl = [['DSL_Standalone',  \n",
        "         round(DSL_mac_auc, 3), \n",
        "         round(DSL_mic_auc, 3), \n",
        "         round(DSL_mac_f1, 3), \n",
        "         round(DSL_mic_f1, 3),\n",
        "         round(DSL_loss, 3),\n",
        "         round(DSL_recall, 3)]]\n",
        "df_dsl = pd.DataFrame(result_dsl, columns=['Model', 'Macro_AUC', 'Micro_AUC', 'Macro_F1', 'Micro_F1', 'Loss', 'Recall@10'])\n",
        "df_dsl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 Miscellaneous"
      ],
      "metadata": {
        "id": "Sigi4WuKeG1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the total running time of the notebook."
      ],
      "metadata": {
        "id": "0qoXT2M3ge5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhjFyQnkSR_7"
      },
      "outputs": [],
      "source": [
        "total_stop = timeit.default_timer()\n",
        "total_duration = str(datetime.timedelta(seconds=round(total_stop - total_start)))\n",
        "total_duration = total_duration.split(\":\")\n",
        "print(f'Notebook finished at {total_stop}')\n",
        "print(f'Total running time of this notebook: {total_duration[0]}h {total_duration[1]}m {total_duration[2]}s')   "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}