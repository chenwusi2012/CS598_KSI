{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Reproducibility Summary"
      ],
      "metadata": {
        "id": "N0vQiW_aeU3u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook reproduces the key experimental result of a paper [1] for the task of automatic medical code prediction from clinical notes using deep neural networks. In this paper, the authors developed an end-to-end framework called Knowledge Source Integration (KSI), which can enhance the state-of-art deep neural networks with the information integration from external knowledge sources. The main contribution of the paper is the development of a neural network to learn the similarity scores between clinical notes and Wikipedia articles about various diseases, and the output similarity scores is then combined with the output from the state-of-art deep neural networks. In the experiment, the clinical notes from MIMIC-III dataset [2] and the Wikipedia articles for ICD-9 diagnosis codes are used as the dataset, and the following four deep neural network models are selected as the baseline models: recurrent neural network (RNN) [3], RNN with attention (RNNatt), convolutional neural network (CNN) [4], and convolutional attention (CAML) [5]. The prediction performance of the standalone baseline models is compared with the baseline models with the KSI framework. The experiment result shows that the KSI framework improves the prediction performance of the selected baseline deep neural networks, and the improvement is particularly large on the prediction of rare medical codes."
      ],
      "metadata": {
        "id": "qNL1NawyfsaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Preparation"
      ],
      "metadata": {
        "id": "seM7lyCOn_g1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfbLDAbD-Ho9"
      },
      "source": [
        "## 2.1 Check GPU Status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0kJAKAWc_4d"
      },
      "source": [
        "This notebook requires hardware acceleration with GPU. Run the following code to make sure the GPU is running."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PysjRxy7Ue3a",
        "outputId": "717f7aed-77e7-43c5-eebb-b4b6f31bb3cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May  4 03:00:43 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTpL8Y_PYIVf"
      },
      "source": [
        "## 2.2 Dataset Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sraXyzOFZFDJ"
      },
      "source": [
        "In this section, the following files are loaded:\n",
        "\n",
        "* `NOTEEVENTS.csv`\n",
        "* `DIAGNOSES_ICD.csv`\n",
        "* `wikipedia_knowledge`\n",
        "* `IDlist.npy`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnmtN942Zvsl"
      },
      "source": [
        "To load `NOTEEVENTS.csv` and `DIAGNOSES_ICD.csv`, take and pass the training \"CITI Data or Specimens Only Research\" at [https://about.citiprogram.org/](https://about.citiprogram.org/), and apply for the access to the MIMIC-III Clinical Database at PhysioNet at [https://physionet.org/content/mimiciii/1.4/](https://physionet.org/content/mimiciii/1.4/). After gaining the access, download `NOTEEVENTS.csv` and `DIAGNOSES_ICD.csv` from PhysioNet, and upload these two CSV files to a created folder \"cs598_project\" in Google drive.\n",
        "  \n",
        "Mount the Google Drive to Google Colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "houR55vShhQE",
        "outputId": "1cee9b03-e7e8-49ea-d0c0-98d533da3d8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l95OzOa5aToH"
      },
      "source": [
        "Display the files in the \"cs598_project\" folder. Make sure `NOTEEVENTS.csv` and `DIAGNOSES_ICD.csv` are uploaded to this folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64ePN8cqnMog",
        "outputId": "d1e2eac9-90ed-4a9c-ed0a-9f9d5e7531a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CAML_model  DIAGNOSES_ICD.csv  KSI_CNN_model\t  KSI_RNN_model   RNNattn_model\n",
            "CNN_model   KSI_CAML_model     KSI_RNNattn_model  NOTEEVENTS.csv  RNN_model\n"
          ]
        }
      ],
      "source": [
        "!ls drive/MyDrive/cs598_project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY0S-SeNammD"
      },
      "source": [
        "Copy `NOTEEVENTS.csv` and `DIAGNOSES_ICD.csv` from Google Drive to Google Colab Runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnsInD8unfwD"
      },
      "outputs": [],
      "source": [
        "!cp drive/MyDrive/cs598_project/DIAGNOSES_ICD.csv DIAGNOSES_ICD.csv\n",
        "!cp drive/MyDrive/cs598_project/NOTEEVENTS.csv NOTEEVENTS.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV4EY3L_a7dJ"
      },
      "source": [
        "`wikipedia_knowledge` and `IDlist.npy` can be downloaded from the GitHub Repository of the original paper ([https://github.com/tiantiantu/KSI](https://github.com/tiantiantu/KSI))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61F2nkrrNlfT",
        "outputId": "f842f60a-af7b-4eca-8a84-e3571e803f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-04 03:01:59--  https://raw.githubusercontent.com/tiantiantu/KSI/master/wikipedia_knowledge\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5311908 (5.1M) [text/plain]\n",
            "Saving to: ‘wikipedia_knowledge’\n",
            "\n",
            "wikipedia_knowledge 100%[===================>]   5.07M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-05-04 03:02:00 (342 MB/s) - ‘wikipedia_knowledge’ saved [5311908/5311908]\n",
            "\n",
            "--2023-05-04 03:02:00--  https://github.com/tiantiantu/KSI/raw/master/IDlist.npy\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/tiantiantu/KSI/master/IDlist.npy [following]\n",
            "--2023-05-04 03:02:00--  https://raw.githubusercontent.com/tiantiantu/KSI/master/IDlist.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 316484 (309K) [application/octet-stream]\n",
            "Saving to: ‘IDlist.npy’\n",
            "\n",
            "IDlist.npy          100%[===================>] 309.07K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2023-05-04 03:02:01 (84.9 MB/s) - ‘IDlist.npy’ saved [316484/316484]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/tiantiantu/KSI/master/wikipedia_knowledge\n",
        "!wget https://github.com/tiantiantu/KSI/raw/master/IDlist.npy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Load Python Files"
      ],
      "metadata": {
        "id": "OKph7reEm6au"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`preprocessing.py`, `training.py`, and `testing.py` contains the functions for data preprocessing, training, and testing of the deep learning models. They can be downloaded from the GitHub repository of this reproduction study ([https://github.com/chenwusi2012/CS598_KSI]())."
      ],
      "metadata": {
        "id": "EDStu2ARKHhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/chenwusi2012/CS598_KSI/main/preprocessing.py\n",
        "!wget https://raw.githubusercontent.com/chenwusi2012/CS598_KSI/main/training.py\n",
        "!wget https://raw.githubusercontent.com/chenwusi2012/CS598_KSI/main/testing.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5BsxpoXnTlX",
        "outputId": "4314b3dd-3394-47be-88a0-add7d548f2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-04 03:02:01--  https://raw.githubusercontent.com/chenwusi2012/CS598_KSI/main/preprocessing.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1717 (1.7K) [text/plain]\n",
            "Saving to: ‘preprocessing.py’\n",
            "\n",
            "preprocessing.py    100%[===================>]   1.68K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-04 03:02:01 (35.2 MB/s) - ‘preprocessing.py’ saved [1717/1717]\n",
            "\n",
            "--2023-05-04 03:02:01--  https://raw.githubusercontent.com/chenwusi2012/CS598_KSI/main/training.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4678 (4.6K) [text/plain]\n",
            "Saving to: ‘training.py’\n",
            "\n",
            "training.py         100%[===================>]   4.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-04 03:02:01 (68.6 MB/s) - ‘training.py’ saved [4678/4678]\n",
            "\n",
            "--2023-05-04 03:02:01--  https://raw.githubusercontent.com/chenwusi2012/CS598_KSI/main/testing.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5172 (5.1K) [text/plain]\n",
            "Saving to: ‘testing.py’\n",
            "\n",
            "testing.py          100%[===================>]   5.05K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-04 03:02:02 (91.6 MB/s) - ‘testing.py’ saved [5172/5172]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Check Loaded Files"
      ],
      "metadata": {
        "id": "LOvDPBiz2L6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if the required files for this notebook have been loaded to the directory."
      ],
      "metadata": {
        "id": "15-MOjAp4MsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "assert os.path.exists('NOTEEVENTS.csv'), \"NOTEEVENTS.csv is not in the directory\"\n",
        "assert os.path.exists('DIAGNOSES_ICD.csv'), \"DIAGNOSES_ICD.csv is not in the directory\"\n",
        "assert os.path.exists('wikipedia_knowledge'), \"wikipedia_knowledge is not in the directory\"\n",
        "assert os.path.exists('IDlist.npy'), \"IDlist.npy is not in the directory\"\n",
        "assert os.path.exists('preprocessing.py'), \"preprocessing.py is not in the directory\"\n",
        "assert os.path.exists('training.py'), \"training.py is not in the directory\"\n",
        "assert os.path.exists('testing.py'), \"testing.py is not in the directory\""
      ],
      "metadata": {
        "id": "eDKtn0x-2UnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSFxY46aet2F"
      },
      "source": [
        "## 2.5 Running Time Tracking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EebpslhDelbO"
      },
      "source": [
        "Import timeit and datetime to track the running time of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv1HPfLA60Nc"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "import datetime\n",
        "total_start = timeit.default_timer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Data Pre-processing"
      ],
      "metadata": {
        "id": "hs7LLN-goPiw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlWdp-4V-aqS"
      },
      "source": [
        "## 3.1 Data Pre-processing 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6t9c0y4ebaW"
      },
      "source": [
        "Install `stop-words` to filter out stop words in the clinical notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHBorULhpNXR",
        "outputId": "f162730b-bcff-4d50-e2e1-f8e8ce81afe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting stop-words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32910 sha256=17602548f5fc828443e746c801cfc44009b4c608654b7c7d9b32fdf874f72b53\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/1a/23/f12552a50cb09bcc1694a5ebb6c2cd5f2a0311de2b8c3d9a89\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ]
        }
      ],
      "source": [
        "!pip install stop-words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the needed Python packages for this section."
      ],
      "metadata": {
        "id": "wKtUOzKfhFT5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lhl6WfZAoeUD"
      },
      "outputs": [],
      "source": [
        "import codecs\n",
        "from collections import defaultdict\n",
        "import csv\n",
        "import string\n",
        "from stop_words import get_stop_words    # download stop words package from https://pypi.org/project/stop-words/\n",
        "import numpy as np\n",
        "import datetime\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record the start timestamp of this section to track the total running time of this section."
      ],
      "metadata": {
        "id": "RZv1K2xzgu83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjxnwUaaGg1i"
      },
      "outputs": [],
      "source": [
        "start = timeit.default_timer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kk0iqHOBo4S"
      },
      "source": [
        "Create a dictionary from `NOTEEVENTS.csv`. The key is `HADM_ID` (ID of a visit), and the value is clinical note.  \n",
        "For clinical note, replace line change with whitespace, remove punctuation, and lowercase all letters.  \n",
        "From paper: \"During preprocessing we lowercased all\n",
        "tokens and removed punctuations, stop words, words containing\n",
        "only digits, and words whose frequency is less than 10\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LVfixu8AVr2"
      },
      "outputs": [],
      "source": [
        "stop_words = get_stop_words('english')\n",
        "\n",
        "admidic=defaultdict(list)\n",
        "num_of_notes=0\n",
        "\n",
        "with open('NOTEEVENTS.csv', 'r') as csvfile:\n",
        "  spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
        "  for row in spamreader: # Iterate all entries in NOTEEVETS\n",
        "    if row[6]=='Discharge summary': # Check if the category is discharge summary\n",
        "      # identify patients through subject_id\n",
        "      # append text to the list of text for a HADM_ID (visit) \n",
        "      # lower case all words, and remove punctuation\n",
        "      admidic[row[2]].append(row[-1].replace('\\n',' ').translate(str.maketrans('','',string.punctuation)).lower())\n",
        "      num_of_notes = num_of_notes+1 # count number of discharge summary notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow1MYjANCmhO"
      },
      "source": [
        "Print the number of notes in `NOTEEVENTS.csv` (From paper: \"The total number of\n",
        "discharge summary notes is 59,652.\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS_gtxj1Ahrv",
        "outputId": "9e286bd1-fc34-4aac-87ec-6cc5c2bad937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of notes in NOTEEVENTS.csv = 59652\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of notes in NOTEEVENTS.csv = {num_of_notes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-cDy3beDLjk"
      },
      "source": [
        "Calculate the word ocurrence (including stop words) in `NOTEEVENTS.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHvu1UZbDc_Z"
      },
      "outputs": [],
      "source": [
        "u=defaultdict(int) # The default count for each word is 0\n",
        "for i in admidic: # for each visit\n",
        "  for jj in admidic[i]: # for each saved note\n",
        "    line=jj.strip('\\n').split() # split into a list of words\n",
        "    for j in line: # Iterate each word\n",
        "      u[j]=u[j]+1 # count the number of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9hfrS-9ENB6"
      },
      "source": [
        "Print the number of words (vocabulary) in `NOTEEVENTS.csv`.  \n",
        "Print the ocurrence of the word \"consistent\" in `NOTEEVENTS.csv`.  \n",
        "Check if the stop word \"the\" in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvhIGKugD0rb",
        "outputId": "a6ca16cd-88ee-416e-ee11-cac4633c73dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in NOTEEVENTS.csv = 529818\n",
            "35831\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of words in NOTEEVENTS.csv = {len(u)}\")\n",
        "print(u[\"consistent\"])\n",
        "print(\"the\" in u)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OiaRFg8E3Ep"
      },
      "source": [
        "Remove the stopwords.  \n",
        "Remove the words whose number of occurence is less than 10.  \n",
        "From paper: \"During preprocessing we lowercased all\n",
        "tokens and removed punctuations, stop words, words containing\n",
        "only digits, and words whose frequency is less than 10\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhdazHeWFFBg"
      },
      "outputs": [],
      "source": [
        "u2=defaultdict(int) # Create a new dict to filter out some words\n",
        "for i in u: # iterate each word\n",
        "  if i.isdigit()==False: # Make sure not a number\n",
        "    if u[i]>10: # Make sure the word occurence is higher than 10\n",
        "      if i not in stop_words: # Make sure not stop words\n",
        "        u2[i]=u[i]\n",
        "num_of_words_in_notes = len(u2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3WioX6eFW3C"
      },
      "source": [
        "Print the number of words (vocabulary) in `NOTEEVENTS.csv` AFTER the removal of stopwords (From paper: \"The final\n",
        "word vocabulary contains 47,965 unique words.\").  \n",
        "Check if the stop word \"the\" in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTGa6IooFTBV",
        "outputId": "b7879c12-05bb-4253-dce2-f152d74e8450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in NOTEEVENTS.csv = 47964\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of words in NOTEEVENTS.csv = {num_of_words_in_notes}\")\n",
        "print(\"the\" in u2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIe0nf07Ij7S"
      },
      "source": [
        "Create a dictionary for `DIAGNOSES_ICD.csv`. The key is `HADM_ID`, and the value if a list of ICD-9 codes for `HADM_ID`.  \n",
        "Add a prefix \"d_\" to the ICD-9 codes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nkbht_bfHum5"
      },
      "outputs": [],
      "source": [
        "u=[]   \n",
        "\n",
        "file1=codecs.open('DIAGNOSES_ICD.csv','r')\n",
        "ad2c=defaultdict(list)\n",
        "line=file1.readline() # Skip the 1st line\n",
        "line=file1.readline() # Read the 2nd line\n",
        "\n",
        "while line:\n",
        "  line=line.strip().split(',') # Split a row into a list\n",
        "\n",
        "  if line[4][1:-1]!='': # If ICD9_CODE column is not empty\n",
        "    ad2c[line[2]].append(\"d_\"+line[4][1:-1]) # Append the code to list of codes for a HADM_ID\n",
        "  \n",
        "  line=file1.readline() # Read the next line"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s98bQUxEJGjl"
      },
      "source": [
        "Print a sample key-value pair (ICD-9 codes for visit 172335)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TygSO_osJPFP",
        "outputId": "5f907e02-fd00-4f47-b69c-6f7f846fce46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['d_40301', 'd_486', 'd_58281', 'd_5855', 'd_4254', 'd_2762', 'd_7100', 'd_2767', 'd_7243', 'd_45829', 'd_2875', 'd_28521', 'd_28529', 'd_27541']\n",
            "14\n"
          ]
        }
      ],
      "source": [
        "print(ad2c[\"172335\"])\n",
        "print(len(ad2c[\"172335\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUuWJPrmKRhv"
      },
      "source": [
        "Calculate the code ocurrence in `DIAGNOSES_ICD.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFsluq1iKNpB"
      },
      "outputs": [],
      "source": [
        "codeu=defaultdict(int)\n",
        "for i in ad2c:\n",
        "  for j in ad2c[i]:\n",
        "    codeu[j]=codeu[j]+1 # counter the occurence of codes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GybgwUEBK2DI"
      },
      "source": [
        "Print the number of unique ICD-9 codes (original codes) in `DIAGNOSES_ICD.csv`.  \n",
        "Print the number of occurence for a code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4K06NaIKkdn",
        "outputId": "cd557f09-35df-4f69-8619-d9c532d6e850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of codes in DIAGNOSES_ICD.csv = 6984\n",
            "4839\n"
          ]
        }
      ],
      "source": [
        "print(f\"number of codes in DIAGNOSES_ICD.csv = {len(codeu)}\")\n",
        "print(codeu[\"d_486\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO0Dyqtc_aaa"
      },
      "source": [
        "Group ICD-9 codes in `DIAGNOSES_ICD.csv` by the first 3 letters (From paper: \"We extracted all\n",
        "listed ICD-9 diagnosis codes for each visit and grouped them by\n",
        "their first three digits\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j6BW_VA9M7j"
      },
      "outputs": [],
      "source": [
        "ad2c2 = defaultdict(list)\n",
        "for hadm_id in ad2c:\n",
        "  for code in ad2c[hadm_id]:\n",
        "    if code[0:5] not in ad2c2[hadm_id]:\n",
        "      ad2c2[hadm_id].append(code[0:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCTpz739_mn6"
      },
      "source": [
        "Print a sample key-value pair (same as the one before ICD-9 code grouping)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cScwSxfM_GCb",
        "outputId": "b2eb82ee-7c5e-430b-facc-799e4ab9b31a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['d_403', 'd_486', 'd_582', 'd_585', 'd_425', 'd_276', 'd_710', 'd_724', 'd_458', 'd_287', 'd_285', 'd_275']\n",
            "12\n"
          ]
        }
      ],
      "source": [
        "print(ad2c2[\"172335\"])\n",
        "print(len(ad2c2[\"172335\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGWvVPCw_xrn"
      },
      "source": [
        "Calculate the code ocurrence in DIAGNOSES_ICD.csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR1NS10fQs6z"
      },
      "outputs": [],
      "source": [
        "codeu2=defaultdict(int)\n",
        "for hadm_id in ad2c2:\n",
        "  for code in ad2c2[hadm_id]:\n",
        "    codeu2[code]=codeu2[code]+1 # counter the occurence of codes\n",
        "num_of_codes_in_notes = len(codeu2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa_vMKj0AEOb"
      },
      "source": [
        "Print the number of unique ICD-9 codes (after grouping) in `DIAGNOSES_ICD.csv` (From paper: \"The code vocabulary contains 942 codes.\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80bKVTDc_Q5W",
        "outputId": "4603db95-1268-4e53-c0a0-b0b0a02c1701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of codes after grouping = 942\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of codes after grouping = {num_of_codes_in_notes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qCjfDnUNifD"
      },
      "source": [
        "Iterate `HADM_ID` in `IDlist.npy`, and combine the code data (from `DIAGNOSES_ICD.csv`) and note data (from `NOTEEVENTS.csv`) into a single file `combined_dataset`.  \n",
        "`combined_dataset`: A dataset contains the clinical notes of hospital visits and corresponding diagnosis (ICD-9 codes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31lmsgy23wPv"
      },
      "outputs": [],
      "source": [
        "fileo=codecs.open(\"combined_dataset\",'w')\n",
        "\n",
        "num_of_aggregated_notes = 0\n",
        "lower_limit_freq = 0\n",
        "upper_limit_freq = 10000000\n",
        "\n",
        "IDlist=np.load('IDlist.npy',encoding='bytes').astype(str) # a list of HADM_ID\n",
        "for hadm_id in IDlist:\n",
        "  if ad2c2[hadm_id]!=[]: # If HADM_ID exists in ad2c\n",
        "    add_to_set = False\n",
        "    for code in ad2c2[hadm_id]:\n",
        "      if codeu2[code] >= lower_limit_freq and codeu2[code] <= upper_limit_freq:\n",
        "        add_to_set = True\n",
        "    if add_to_set:\n",
        "      fileo.write('start! '+i+'\\n')\n",
        "      fileo.write('codes: ')\n",
        "      tempc=[]\n",
        "      for code in ad2c2[hadm_id]: # for each code\n",
        "        if codeu2[code] >= lower_limit_freq and codeu2[code] <= upper_limit_freq: # if code occurence greater than threshold\n",
        "          if code not in tempc:\n",
        "            tempc.append(code) # save d_ and first 3 digits of ICD-9 code\n",
        "      \n",
        "      for code in tempc:\n",
        "        fileo.write(code+\" \") # write code to combined dataset\n",
        "      fileo.write('\\n')\n",
        "      fileo.write('notes:\\n') # write note\n",
        "      for line in admidic[hadm_id]: # iterate each line    \n",
        "        thisline=line.strip('\\n').split() \n",
        "        for j in thisline: # iterate each word\n",
        "          if u2[j]!=0: # if this word is a qualified word\n",
        "            fileo.write(j+\" \") # write this word\n",
        "          fileo.write('\\n')\n",
        "      fileo.write('end!\\n')\n",
        "      num_of_aggregated_notes = num_of_aggregated_notes + 1\n",
        "fileo.close()\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olb3AGDhEI-x"
      },
      "source": [
        "Print the number of note-code pairs added to the dataset (From paper:\"The number of aggregated discharge summary notes is 52,722..\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhzMBfP7D_qe",
        "outputId": "ace0b5b0-4e25-4eec-febc-46347352d768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of notes written to combined dataset = 52722\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of notes written to combined dataset = {num_of_aggregated_notes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the total running time of this section."
      ],
      "metadata": {
        "id": "ewGvvJBtg2aH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZDh7aDeD_fY",
        "outputId": "a435132d-9263-4cba-a3f4-3859faea05b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time duration: 0h 01m 44s\n"
          ]
        }
      ],
      "source": [
        "stop = timeit.default_timer()\n",
        "duration = str(datetime.timedelta(seconds=round(stop-start)))\n",
        "duration = duration.split(\":\")\n",
        "print(f'Time duration: {duration[0]}h {duration[1]}m {duration[2]}s') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COK-Hrv5-knl"
      },
      "source": [
        "## 3.2 Data Pre-processing 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the needed Python packages for this section."
      ],
      "metadata": {
        "id": "_5jp7zUZhIcd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yrbstc1758MT"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record the start timestamp of this section to track the total running time of this section."
      ],
      "metadata": {
        "id": "4yRFj1UOgxBj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLfX0hlBGsBK"
      },
      "outputs": [],
      "source": [
        "start = timeit.default_timer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f2ORuVJIlnU"
      },
      "source": [
        "Build a vocabulary for Wiki documents. The key is a word, and the value is 1 if the word exists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5kSmQc3ImLq"
      },
      "outputs": [],
      "source": [
        "wikivocab={}\n",
        "file1=codecs.open(\"wikipedia_knowledge\",'r','utf-8')\n",
        "line=file1.readline()\n",
        "while line:\n",
        "  if line[0:3]!='XXX': # if this line is not start or end of doc\n",
        "    line=line.strip('\\n')\n",
        "    line=line.split()\n",
        "    for i in line: # iterate each word\n",
        "      wikivocab[i.lower()]=1 # if a word exists in doc, set to 1\n",
        "  line=file1.readline()\n",
        "num_of_words_in_wiki = len(wikivocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxyybgFLJgNK"
      },
      "source": [
        "Print the size of the vocabulary for Wiki documents (From paper: \"The size\n",
        "of the word vocabulary of Wikipedia documents is 60,968.\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4tCwHxXJDwi",
        "outputId": "ba38695e-3559-42fe-855d-dce291541e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique words in Wiki documents = 60968\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of unique words in Wiki documents = {num_of_words_in_wiki}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOo0A3-9KEAC"
      },
      "source": [
        "Build a vocabulary for `NOTEEVENTS.csv` (after word processing). The key is a word, and the value is 1 if the word exists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "In7y-or4KWE8"
      },
      "outputs": [],
      "source": [
        "notesvocab={}\n",
        "filec=codecs.open(\"combined_dataset\",'r','utf-8')\n",
        "\n",
        "line=filec.readline()\n",
        "\n",
        "while line:\n",
        "  line=line.strip('\\n')\n",
        "  line=line.split()\n",
        "  \n",
        "  if line[0]=='codes:':\n",
        "    line=filec.readline()\n",
        "    line=line.strip('\\n')\n",
        "    line=line.split()\n",
        "    \n",
        "    if line[0]=='notes:': \n",
        "      line=filec.readline()\n",
        "      while line!='end!\\n':\n",
        "        line=line.strip('\\n')\n",
        "        line=line.split()\n",
        "        for word in line:\n",
        "          notesvocab[word]=1\n",
        "        line=filec.readline()            \n",
        "  line=filec.readline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPXbUzq6LcRR"
      },
      "source": [
        "Print the size of vocabulary for `NOTEEVENTS.csv` after word processing (From paper: \"The final word vocabulary contains 47,965 unique words.\").  \n",
        "Print a sample key-value pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtN8IgIZK_pY",
        "outputId": "432c6b00-193f-4a81-e203-f4ba5ef5d6ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47964\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "print(len(notesvocab))\n",
        "print(notesvocab[\"consistent\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3VGW7dkL_PE"
      },
      "source": [
        "Get an intersection of the vocabulary for wiki documents and the one for `NOTEVENTS.csv`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9JMMHhiMITq"
      },
      "outputs": [],
      "source": [
        "a1=set(notesvocab)\n",
        "a2=set(wikivocab)\n",
        "a3=a1.intersection(a2) # get the intersection\n",
        "num_of_words_in_both = len(a3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ladA4oybMY73"
      },
      "source": [
        "Print number of unique words in the intersection (From paper: \"The size of the word vocabulary of Wikipedia documents is 60,968, out of which only 12,173 are also in the word vocabulary of MIMIC-III clinical notes.\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcJK3dukMeYS",
        "outputId": "234f72a5-42c9-4ed6-d130-588a3bc37500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12173\n"
          ]
        }
      ],
      "source": [
        "print(num_of_words_in_both)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYZxImH0NdDf"
      },
      "source": [
        "Create a list of lists. Each element list is a list of intersected words for one Wiki document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHj2uu7SNaQn"
      },
      "outputs": [],
      "source": [
        "wikidocuments=[] # a list of lists, each element is a list of intersected and filtered words for one doc\n",
        "file2=codecs.open(\"wikipedia_knowledge\",'r','utf-8')\n",
        "line=file2.readline() \n",
        "while line:\n",
        "  if line[0:4]=='XXXd': # Check if it is a start of a wiki doc\n",
        "    tempf=[]\n",
        "    line=file2.readline() # read the next line\n",
        "    while line[0:4]!='XXXe': # keep reading until the end of that doc\n",
        "      line=line.strip('\\n')\n",
        "      words=line.split()\n",
        "      for word in words:\n",
        "        if word.lower() in a3: # if this word also appears in note\n",
        "          tempf.append(word.lower()) # add this word to the list for this doc\n",
        "      line=file2.readline()\n",
        "    wikidocuments.append(tempf) # add word list of doc to list of docs \n",
        "  line=file2.readline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSeBdRaHOF3p"
      },
      "source": [
        "Print number of elements in wikidocuments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLfOCUqBN7o1",
        "outputId": "5eed6cab-e028-469a-e672-0f3a3a8b332e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "325\n"
          ]
        }
      ],
      "source": [
        "print(len(wikidocuments))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcK34TJLO9yM"
      },
      "source": [
        "Create a list of lists. Each element list is a list of intersected words for one clinical note."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjmPcDD6PCY1"
      },
      "outputs": [],
      "source": [
        "notesdocuments=[] # a list of lists, each element is a list of intersected and filtered words for one note\n",
        "file3=codecs.open(\"combined_dataset\",'r','utf-8')\n",
        "line=file3.readline()\n",
        "while line:\n",
        "  line=line.strip('\\n')\n",
        "  line=line.split()\n",
        "  if line[0]=='codes:': # if this line is for code\n",
        "    line=file3.readline() # skip this line\n",
        "    line=line.strip('\\n')\n",
        "    line=line.split()\n",
        "    if line[0]=='notes:': # if this line is for note\n",
        "      tempf=[]\n",
        "      line=file3.readline()\n",
        "      while line!='end!\\n': # keep reading until the end of the note\n",
        "        line=line.strip('\\n')\n",
        "        line=line.split()\n",
        "        for word in line:\n",
        "          if word in a3:\n",
        "            tempf.append(word)     \n",
        "        line=file3.readline()      \n",
        "      notesdocuments.append(tempf)\n",
        "  line=file3.readline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgP1wKEWSVV2"
      },
      "source": [
        "Set the sequence of words in the vocabulary matrix. Key is a word, and the value is the sequence/order in the vocabulary matrix.  \n",
        "This is a preparation for building the matrices of the intersected words for Wiki documents and clinical notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGwAnUihS5sY"
      },
      "outputs": [],
      "source": [
        "notesvocab={}\n",
        "for i in notesdocuments: # for each element (is a list) in list\n",
        "  for j in i: # for each word\n",
        "    if j.lower() not in notesvocab: # if a word is not in dict\n",
        "      # # set value of this word equal to current element (order of the token in matrix)\n",
        "      notesvocab[j.lower()]=len(notesvocab) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiUuPs8lTaow"
      },
      "source": [
        "Print sample key-value pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4bUiVMrTd67",
        "outputId": "ae25019b-e1a8-4081-fd38-fa79bfd9ed06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "print(notesvocab[\"admission\"])\n",
        "print(notesvocab[\"date\"])\n",
        "print(notesvocab[\"discharge\"])\n",
        "print(notesvocab[\"birth\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RKZthpkV8g1"
      },
      "source": [
        "Create a list of string for Wiki document, and each element is a string for a Wiki document (including intersected words).\n",
        "This is a preparation for building the matrices of the intersected words for Wiki documents and clinical notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWcFW-QEV63H"
      },
      "outputs": [],
      "source": [
        "wikidata=[] # each element is a string, each string contains words for a wiki doc\n",
        "for i in wikidocuments:\n",
        "  temp=''\n",
        "  for j in i:\n",
        "    temp=temp+j+\" \"\n",
        "  wikidata.append(temp)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te_XDGn_VFlV"
      },
      "source": [
        "Create a list of string for clinical notes, and each element is a string for a note (including intersected words).  \n",
        "This is a preparation for building the matrices of the intersected words for Wiki documents and clinical notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsxeKIhJVEI8"
      },
      "outputs": [],
      "source": [
        "notedata=[] # each element is a string, each string contains words for a note\n",
        "for i in notesdocuments: # for each element (list) in list\n",
        "  temp=''\n",
        "  for j in i: # for each word\n",
        "    temp=temp+j+\" \" # create a string, words for a note separated by a space\n",
        "  notedata.append(temp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-zZsHsfZETc"
      },
      "source": [
        "Create 2 word matrices (intersected words). One is for Wiki documents, and the other is for clinical notes.  \n",
        "`notevec`: A matrix of intersected words for clinical notes.  \n",
        "`wikivec`: A matrix of intersected words for Wiki documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBfUhADjZVha"
      },
      "outputs": [],
      "source": [
        "# create a matrix of token counts\n",
        "vect = CountVectorizer(min_df=1,vocabulary=notesvocab,binary=True)\n",
        "# transfer list of string to matrix, if a word exists in a string, set value to 1\n",
        "binaryn = vect.fit_transform(notedata)\n",
        "binaryn=binaryn.A # Return self as an ndarray object.\n",
        "binaryn=np.array(binaryn,dtype=float)\n",
        "\n",
        "vect2 = CountVectorizer(min_df=1,vocabulary=notesvocab,binary=True)\n",
        "binaryk = vect2.fit_transform(wikidata)\n",
        "binaryk=binaryk.A\n",
        "binaryk=np.array(binaryk,dtype=float)\n",
        "notevec = binaryn\n",
        "wikivec = binaryk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDe_Hdt2Zy7s"
      },
      "source": [
        "Print the shape of the created matrices.  \n",
        "For the matrix for clinical notes, the size of 1st dimension is the number of notes, and the size of the 2nd dimension is the number of intersected words.  \n",
        "For the matrix for Wiki documents, the size of 1st dimension is the number of Wiki documents, and the size of the 2nd dimension is the number of intersected words.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alNBP-KwZ3L7",
        "outputId": "90db8716-fea2-4e0a-eed7-68765bb17bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the matrix for clinical notes (notevec) = (52722, 12173)\n",
            "The shape of the matrix for wiki docs (wikivec) = (325, 12173)\n"
          ]
        }
      ],
      "source": [
        "print(f\"The shape of the matrix for clinical notes (notevec) = {binaryn.shape}\")\n",
        "print(f\"The shape of the matrix for wiki docs (wikivec) = {binaryk.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the total running time of this section."
      ],
      "metadata": {
        "id": "-Ku4DbKig4gD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4Bc7NWJ6TuA",
        "outputId": "9e69cb5b-b0d7-4103-8220-74a9c5d10017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time duration: 0h 04m 16s\n"
          ]
        }
      ],
      "source": [
        "stop = timeit.default_timer()\n",
        "duration = str(datetime.timedelta(seconds=round(stop-start)))\n",
        "duration = duration.split(\":\")\n",
        "print(f'Time duration: {duration[0]}h {duration[1]}m {duration[2]}s')   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA3PKA3o-zIW"
      },
      "source": [
        "## 3.3 Data Pre-processing 3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the needed Python packages for this section."
      ],
      "metadata": {
        "id": "6pJLOFLqhJTZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmglWv6s9Jhc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record the start timestamp of this section to track the total running time of this section."
      ],
      "metadata": {
        "id": "rZAhvfuJgyVp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqMqsHWScDco"
      },
      "outputs": [],
      "source": [
        "start = timeit.default_timer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dMkHxzFeEGD"
      },
      "source": [
        "Create 2 dictionaries for the ICD-9 codes for Wiki documents.  \n",
        "For the 1st dictionary, the key is a ICD-9 code which exists in Wiki documents, and the value is 1.\n",
        "For the 2nd dictionary, the key is a ICD-9 code which exists in Wiki documents, and the value is the list which contain the sequence number of Wiki documents for this ICD-9 code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNU5O0HNcLOB"
      },
      "outputs": [],
      "source": [
        "wikivoc={}\n",
        "codewiki=defaultdict(list)\n",
        "\n",
        "file2=codecs.open(\"wikipedia_knowledge\",'r','utf-8')\n",
        "line=file2.readline()\n",
        "count=0\n",
        "while line:\n",
        "  if line[0:4]=='XXXd': # read the start of a wiki doc\n",
        "    line=line.strip('\\n')\n",
        "    codes=line.split()\n",
        "    for code in codes:\n",
        "      if code[0:2]=='d_': # if it is a icd code\n",
        "        codewiki[code].append(count) # save the index of wiki doc to list for code\n",
        "        wikivoc[code]=1 # set value of code to 1\n",
        "    count=count+1\n",
        "  line=file2.readline()\n",
        "  num_of_codes_in_wiki = len(wikivoc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI6vsnX0gObv"
      },
      "source": [
        "Print the number of ICD-9 codes in Wiki documents (**not all of them can be found in clinical notes**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TCFIlvqcQ4B",
        "outputId": "58b407b9-422e-4dcd-a6c1-1becde5ac830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of codes = 389\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total number of codes = {num_of_codes_in_wiki}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXmyJz6chflJ"
      },
      "source": [
        "Each of the following 4 ICD-9 codes appears in 2 Wiki documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZR9TGFAhDM2",
        "outputId": "1b1d287a-7e09-417c-8237-54967e5f14c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[47, 214]\n",
            "[106, 125]\n",
            "[149, 250]\n",
            "[219, 221]\n"
          ]
        }
      ],
      "source": [
        "print(codewiki['d_072'])\n",
        "print(codewiki['d_698'])\n",
        "print(codewiki['d_305'])\n",
        "print(codewiki['d_386'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXlRQZ4khr9V"
      },
      "source": [
        "For training purpose, each Wiki document can have more than one ICD-9 code, but each ICD-9 code can appear in only one Wiki document.  \n",
        "Correct the 4 ICD-9 codes above, and for each of these 4 codes, down-select one Wiki document.  \n",
        "`wikivoc`: A matrix of ICD-9 codes which appear in Wiki documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFSJFFcriWRC"
      },
      "outputs": [],
      "source": [
        "codewiki['d_072']=[214]\n",
        "codewiki['d_698']=[125]\n",
        "codewiki['d_305']=[250]\n",
        "codewiki['d_386']=[219]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRJq3pVJOZHO"
      },
      "source": [
        "Prepare feature and label for the deep learning model.  \n",
        "Feature: A list of string. Each string is one clinical note.  \n",
        "Label: A list of string. Each string is the ICD-9 codes for one clinical note."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EM3pmjJZOTEX"
      },
      "outputs": [],
      "source": [
        "filec=codecs.open(\"combined_dataset\",'r','utf-8')\n",
        "\n",
        "line=filec.readline()\n",
        "\n",
        "feature=[]\n",
        "label=[]\n",
        "\n",
        "while line:\n",
        "  line=line.strip('\\n')\n",
        "  line=line.split()\n",
        "  \n",
        "  if line[0]=='codes:':\n",
        "    temp=line[1:] # read the codes of that node\n",
        "    label.append(temp) # add the code to list for label\n",
        "    line=filec.readline()\n",
        "    line=line.strip('\\n')\n",
        "    line=line.split()\n",
        "    if line[0]=='notes:':\n",
        "      tempf=[]\n",
        "      line=filec.readline()\n",
        "      \n",
        "      while line!='end!\\n': # read the notes until end\n",
        "        line=line.strip('\\n')\n",
        "        line=line.split()\n",
        "        tempf=tempf+line\n",
        "        line=filec.readline()\n",
        "      feature.append(tempf) # add list of words to list of feature\n",
        "  line=filec.readline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4la9dYtOTPLz"
      },
      "source": [
        "Create the sequence for label (ICD-9 codes). The key is a ICD-9 code, and the value is the sequence of a ICD-9 code in the code vector later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrzF4EYGTksY"
      },
      "outputs": [],
      "source": [
        "prevoc={}\n",
        "for i in label:\n",
        "  for j in i:\n",
        "    if j not in prevoc:\n",
        "      prevoc[j] = len(prevoc) # set up the order of codes (for vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skouqwX8TtHz"
      },
      "source": [
        "Print a sample key-value pairs (refer to `label[0]`).  \n",
        "Print the number of key-value pairs (codes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8zU8E3uTwvn",
        "outputId": "55411fcb-5e11-4276-f273-db10cb8f89ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "941\n"
          ]
        }
      ],
      "source": [
        "print(prevoc[\"d_486\"])\n",
        "print(prevoc[\"d_518\"])\n",
        "print(prevoc[\"d_511\"])\n",
        "print(len(prevoc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvRlVNfjVgon"
      },
      "source": [
        "Create mapping between ICD-9 codes and the index in the code vector by 2 dictionaries.  \n",
        "**This mapping is for all codes found in the combined dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxSZbDm9Vq9N"
      },
      "outputs": [],
      "source": [
        "label_to_ix = {}\n",
        "ix_to_label = {}\n",
        "\n",
        "# create a mapping between code and index\n",
        "for codes in label:\n",
        "  for code in codes:\n",
        "    if code not in label_to_ix:\n",
        "      label_to_ix[code]=len(label_to_ix)\n",
        "      ix_to_label[label_to_ix[code]]=code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz3jD8rBWDYa"
      },
      "source": [
        "Print sample key-value pairs.  \n",
        "Print the number of ICD-9 codes found in combined dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk3ABC2ZWGfM",
        "outputId": "91b24abc-160e-40fd-cc5c-8f968833ddd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "d_486\n",
            "Total number of codes = 941\n"
          ]
        }
      ],
      "source": [
        "print(label_to_ix[\"d_486\"])\n",
        "print(ix_to_label[0])\n",
        "print(f\"Total number of codes = {len(label_to_ix)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4JxLlXIfI8_"
      },
      "source": [
        "Create a word vector (intersected words) for each of the ICD-9 codes found in combined_dataset.\n",
        "*   If a ICD-9 code can be found in Wiki documents: label index -> ICD-9 code -> sequence/index of Wiki document -> vector of intersected words of Wikidocument (1 x number of intersected words).\n",
        "*   If ICD-9 code cannot be found in Wiki document: zero vector in shape of (1 x number of intersected words).\n",
        "Create a mapping between ICD-9 code index in label and corresponding "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m7qfTVDeap9"
      },
      "outputs": [],
      "source": [
        "tempwikivec=[]\n",
        "\n",
        "for i in range(0,len(ix_to_label)):\n",
        "  if ix_to_label[i] in wikivoc: # if a code in note can be found in wiki docs\n",
        "    temp=wikivec[codewiki[ix_to_label[i]][0]] # save wiki doc index to temp\n",
        "    tempwikivec.append(temp)\n",
        "  else:\n",
        "    tempwikivec.append([0.0]*wikivec.shape[1])\n",
        "wikivec=np.array(tempwikivec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh67nu1Mi-XD"
      },
      "source": [
        "Print sample result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0sD4EbodGiT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99e541fa-3892-4062-8020-10573c2453ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If the ICD-9 code is = d_486\n",
            "The index of the corresponding wiki doc = [167]\n",
            "The index of the corresponding wiki doc = 167\n",
            "The vector of intersected words for the corresponding wiki doc = [0. 0. 0. ... 0. 0. 0.]\n",
            "The shape of the vector is = (12173,)\n"
          ]
        }
      ],
      "source": [
        "print(f\"If the ICD-9 code is = {ix_to_label[0]}\")\n",
        "print(f\"The index of the corresponding wiki doc = {codewiki[ix_to_label[0]]}\")\n",
        "print(f\"The index of the corresponding wiki doc = {codewiki[ix_to_label[0]][0]}\")\n",
        "print(f\"The vector of intersected words for the corresponding wiki doc = {wikivec[codewiki[ix_to_label[0]][0]]}\")\n",
        "print(f\"The shape of the vector is = {wikivec[codewiki[ix_to_label[0]][0]].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWwAFL04ktBd"
      },
      "source": [
        "Create dataset. The dataset contains 3 parts:\n",
        "*   Feature: a list of lists, and each element is a list of words (strings) for one clinical note.\n",
        "*   Notevec: a list of vectors, and each element is a vector of intersected words for one clinical note.\n",
        "*   Label: a list of lists, and each element is a list of ICD-codes for one clinical note."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9OSJf1Nec4t"
      },
      "outputs": [],
      "source": [
        "data=[]\n",
        "for i in range(0,len(feature)):\n",
        "  # save feature (list of words for note), note matrix and label (code) as a tuple\n",
        "  data.append((feature[i], notevec[i], label[i]))\n",
        "    \n",
        "data=np.array(data, dtype=object)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xbg7p7InnXq"
      },
      "source": [
        "Create mapping between ICD-9 codes and the index in the code vector by 2 dictionaries.  \n",
        "**Different from previous `label_to_ix` and `ix_to_label`, this mapping is for ICD-9 codes found in Wiki documents only.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiEMkZjkelOm"
      },
      "outputs": [],
      "source": [
        "label_to_ix = {}\n",
        "ix_to_label = {}\n",
        "\n",
        "for doc, note, codes in data:\n",
        "  for code in codes:\n",
        "    if code not in label_to_ix:\n",
        "      if code in wikivoc:\n",
        "        label_to_ix[code]=len(label_to_ix)\n",
        "        ix_to_label[label_to_ix[code]]=code\n",
        "\n",
        "num_of_codes_in_both = len(label_to_ix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRTLBW7dqUgf"
      },
      "source": [
        "Print sample key-value pairs.  \n",
        "Print the number of ICD-9 codes which **exists in both clinical notes and Wiki documents** (From paper: \"Of those codes, we selected a subset of 344 codes for which we found the corresponding Wikipedia document and used those codes in our experiments.\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUc2UUh-nMqZ",
        "outputId": "e6424107-036a-4317-9bbf-6a5e59f83d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "d_486\n",
            "Total number of codes = 344\n"
          ]
        }
      ],
      "source": [
        "print(label_to_ix[\"d_486\"])\n",
        "print(ix_to_label[0])\n",
        "print(f\"Total number of codes = {num_of_codes_in_both}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x2BllzNvJnH"
      },
      "source": [
        "Split training data, validation data, and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90BcKLLXerYC"
      },
      "outputs": [],
      "source": [
        "training_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "training_data, val_data = train_test_split(training_data, test_size=0.125, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYfRRu_pB2K7"
      },
      "source": [
        "Create index for words in clinical notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNJKARBVeuI4"
      },
      "outputs": [],
      "source": [
        "word_to_ix = {}\n",
        "ix_to_word={}\n",
        "ix_to_word[0]='OUT'\n",
        "\n",
        "for doc, note, codes in training_data:\n",
        "  for word in doc:\n",
        "    if word not in word_to_ix:\n",
        "      word_to_ix[word] = len(word_to_ix)+1\n",
        "      ix_to_word[word_to_ix[word]]=word  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Pl1zvOmGHBt"
      },
      "source": [
        "Print sample key-value pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiidFU4cDLtV",
        "outputId": "010ee743-395c-40bb-823a-261b79464878"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUT\n",
            "admission\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "print(ix_to_word[0])\n",
        "print(ix_to_word[1])\n",
        "print(word_to_ix['admission'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YRAJ4AtJuem"
      },
      "source": [
        "Create a word vector (intersected words) for each of the ICD-9 codes found in **both Wiki document and clinical notes (combined dataset)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_VMHm0Eewv5"
      },
      "outputs": [],
      "source": [
        "newwikivec=[]\n",
        "for i in range(0,len(ix_to_label)):\n",
        "  newwikivec.append(wikivec[prevoc[ix_to_label[i]]])\n",
        "newwikivec=np.array(newwikivec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGp0wg9QKHSx"
      },
      "source": [
        "Print sample result.  \n",
        "Print the number of vectors in wikivec and newwikivec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWdQx4t0Hb7g",
        "outputId": "944289f4-5163-47e4-ebb1-c66e473d5f29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d_486\n",
            "0\n",
            "[1. 0. 0. ... 0. 0. 0.]\n",
            "344\n",
            "941\n"
          ]
        }
      ],
      "source": [
        "print(ix_to_label[0])\n",
        "print(prevoc[ix_to_label[0]])\n",
        "print(wikivec[prevoc[ix_to_label[0]]])\n",
        "print(len(newwikivec))\n",
        "print(len(wikivec))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the total running time of this section."
      ],
      "metadata": {
        "id": "yI8kbChFg70V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3bF8Y-_817e",
        "outputId": "0fddd16f-9407-40dc-da8f-46b123fbd3d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time duration: 0h 04m 19s\n"
          ]
        }
      ],
      "source": [
        "stop = timeit.default_timer()\n",
        "duration = str(datetime.timedelta(seconds=round(stop-start)))\n",
        "duration = duration.split(\":\")\n",
        "print(f'Time duration: {duration[0]}h {duration[1]}m {duration[2]}s')  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Data Pre-processing 4"
      ],
      "metadata": {
        "id": "ZaFHYR_R0NLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform data processing on the training dataset, validation dataset, and test dataset. The function `preprocessing` can be found in `preprocessing.py`."
      ],
      "metadata": {
        "id": "lJMuRf_broxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "from preprocessing import preprocessing\n",
        "\n",
        "\n",
        "wikisize=newwikivec.shape[0]\n",
        "rvocsize=newwikivec.shape[1]\n",
        "wikivec=autograd.Variable(torch.FloatTensor(newwikivec))\n",
        "\n",
        "batchsize = 32\n",
        "\n",
        "batchtraining_data=preprocessing(training_data, label_to_ix, word_to_ix, wikivoc, batchsize)\n",
        "batchtest_data=preprocessing(test_data, label_to_ix, word_to_ix, wikivoc, batchsize)\n",
        "batchval_data=preprocessing(val_data, label_to_ix, word_to_ix, wikivoc, batchsize) "
      ],
      "metadata": {
        "id": "-UGuOeuZ0Sdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNEqr0QqvXan"
      },
      "source": [
        "# 4 Data Statistics (Overview of Data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijIWWAC91OPo"
      },
      "source": [
        "The following table shows the statistics of the ***clinical notes from MIMIC-III dataset***. The values in the following table match the statistics in section 4.1 of the original paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "-U-LLj2FvY6L",
        "outputId": "ab0cfb44-af5e-4a9f-a227-92cb6945fe85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     Statistics  Result\n",
              "0             Number of discharge summary notes   59652\n",
              "1  Number of aggregated discharge summary notes   52722\n",
              "2    Number of words in discharge summary notes   47964\n",
              "3    Number of codes in discharge summary notes     942"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ba38e4f-8e3b-483a-aab8-7f0884dd5c29\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Number of discharge summary notes</td>\n",
              "      <td>59652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Number of aggregated discharge summary notes</td>\n",
              "      <td>52722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Number of words in discharge summary notes</td>\n",
              "      <td>47964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Number of codes in discharge summary notes</td>\n",
              "      <td>942</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ba38e4f-8e3b-483a-aab8-7f0884dd5c29')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ba38e4f-8e3b-483a-aab8-7f0884dd5c29 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ba38e4f-8e3b-483a-aab8-7f0884dd5c29');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "note_stat = []\n",
        "note_stat.append([\"Number of discharge summary notes\", num_of_notes])\n",
        "note_stat.append([\"Number of aggregated discharge summary notes\", num_of_aggregated_notes])\n",
        "note_stat.append([\"Number of words in discharge summary notes\", num_of_words_in_notes])\n",
        "note_stat.append([\"Number of codes in discharge summary notes\", num_of_codes_in_notes])\n",
        "df_note_stat = pd.DataFrame(note_stat, columns=['Statistics', 'Result'])\n",
        "df_note_stat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYswSNMq7koA"
      },
      "source": [
        "The following table shows the statistics of the ***Wikipedia articles for ICD-9 diagnosis codes***. The values in the following table match the statistics in section 4.1 of the original paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "LDlas4s810yZ",
        "outputId": "6b9a1a2a-ea45-4b72-e717-590692969d42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               Statistics  Result\n",
              "0        Number of words in Wiki articles   60968\n",
              "1        Number of codes in Wiki articles     389\n",
              "2  Number of words in both Wiki and notes   12173\n",
              "3  Number of codes in both Wiki and notes     344"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0b2bcd2-f969-401f-b080-82f5ebc8cf38\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statistics</th>\n",
              "      <th>Result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Number of words in Wiki articles</td>\n",
              "      <td>60968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Number of codes in Wiki articles</td>\n",
              "      <td>389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Number of words in both Wiki and notes</td>\n",
              "      <td>12173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Number of codes in both Wiki and notes</td>\n",
              "      <td>344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0b2bcd2-f969-401f-b080-82f5ebc8cf38')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0b2bcd2-f969-401f-b080-82f5ebc8cf38 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0b2bcd2-f969-401f-b080-82f5ebc8cf38');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "wiki_stat = []\n",
        "num_of_words_in_wiki\n",
        "wiki_stat.append([\"Number of words in Wiki articles\", num_of_words_in_wiki])\n",
        "wiki_stat.append([\"Number of codes in Wiki articles\", num_of_codes_in_wiki])\n",
        "wiki_stat.append([\"Number of words in both Wiki and notes\", num_of_words_in_both])\n",
        "wiki_stat.append([\"Number of codes in both Wiki and notes\", num_of_codes_in_both])\n",
        "df_wiki_stat = pd.DataFrame(wiki_stat, columns=['Statistics', 'Result'])\n",
        "df_wiki_stat"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5 Training and Testing of Models"
      ],
      "metadata": {
        "id": "aCxeDVhmoeI8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aalecYXO-8lt"
      },
      "source": [
        "## 5.1 Convolutional Attention (CAML)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section compares the performance of the following models in the task of ICD-9 diagnosis code prediction from the clinical notes in MIMIC-III dataset:\n",
        "\n",
        "\n",
        "*   Standalone model of convolutional attention (CAML).\n",
        "*   Convolutional attention model with the KSI framework (KSI+CAML).\n",
        "\n",
        "First, import the needed Python packages for this section."
      ],
      "metadata": {
        "id": "V0wl-PsCV1Ev"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDfshwRU9jvC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "torch.manual_seed(1)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "import copy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record the start timestamp of this section to track the total running time of this section."
      ],
      "metadata": {
        "id": "vIWCQMFqX1YM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = timeit.default_timer()"
      ],
      "metadata": {
        "id": "7wdBWP6Ilm4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the standalone CAML model and the CAML model with the KSI framework."
      ],
      "metadata": {
        "id": "_Jus4qx1YT6t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okDHhv5Hu6dx"
      },
      "outputs": [],
      "source": [
        "Embeddingsize = 100\n",
        "hidden_dim = 200\n",
        "\n",
        "class CAML(nn.Module):\n",
        "\n",
        "    def __init__(self, batch_size, vocab_size, tagset_size):\n",
        "        super(CAML, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.word_embeddings = nn.Embedding(vocab_size+1, Embeddingsize, padding_idx=0)\n",
        "        self.embed_drop = nn.Dropout(p=0.2)   \n",
        "        \n",
        "        \n",
        "        self.convs1 = nn.Conv1d(Embeddingsize,300,10,padding=5)\n",
        "        self.H=nn.Linear(300, tagset_size )   \n",
        "        self.final = nn.Linear(300, tagset_size)\n",
        "        \n",
        "        self.layer2 = nn.Linear(Embeddingsize, 1)\n",
        "        self.embedding=nn.Linear(rvocsize,Embeddingsize,bias=False)\n",
        "        self.vattention=nn.Linear(Embeddingsize,Embeddingsize)\n",
        "        \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "    \n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "    \n",
        "    def forward(self, vec1, nvec, wiki, simlearning):\n",
        "        \n",
        "       \n",
        "        thisembeddings=self.word_embeddings(vec1)\n",
        "        thisembeddings = self.embed_drop(thisembeddings)\n",
        "        thisembeddings=thisembeddings.transpose(1,2)\n",
        "        \n",
        "        \n",
        "        thisembeddings=self.tanh(self.convs1(thisembeddings).transpose(1,2))  \n",
        "        \n",
        "        alpha=self.H.weight.matmul(thisembeddings.transpose(1,2))\n",
        "        alpha=F.softmax(alpha, dim=2)\n",
        "        \n",
        "        m=alpha.matmul(thisembeddings)\n",
        "       \n",
        "        myfinal=self.final.weight.mul(m).sum(dim=2).add(self.final.bias)\n",
        "        \n",
        "        if simlearning==1:\n",
        "            nvec=nvec.view(batchsize,1,-1)\n",
        "            nvec=nvec.expand(batchsize,wiki.size()[0],-1)\n",
        "            wiki=wiki.view(1,wiki.size()[0],-1)\n",
        "            wiki=wiki.expand(nvec.size()[0],wiki.size()[1],-1)\n",
        "            new=wiki*nvec\n",
        "            new=self.embedding(new)\n",
        "            vattention=self.sigmoid(self.vattention(new))\n",
        "            new=new*vattention\n",
        "            vec3=self.layer2(new)\n",
        "            vec3=vec3.view(batchsize,-1)\n",
        "        \n",
        "       \n",
        "        if simlearning==1:\n",
        "            tag_scores = self.sigmoid(myfinal.detach()+vec3)\n",
        "        else:\n",
        "            tag_scores = self.sigmoid(myfinal)\n",
        "              \n",
        "        return tag_scores "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the standalone CAML model and the CAML model with the KSI framework. The training will stop if the top-10 recall score does not improve on the validation dataset in the next 5 epochs. The function `trainmodel` can be found in `training.py`."
      ],
      "metadata": {
        "id": "UE94KudHYgkt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lXtJz6GunsQ",
        "outputId": "ab4bc8a5-3abc-4714-d047-9e313be3e349"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max epochs = 5000\n",
            "Train basemodel\n",
            "epoch = 0\n",
            "validation recall @ top- 10 0.6044048484082241\n",
            "Update the best model to epoch 0\n",
            "epoch = 1\n",
            "validation recall @ top- 10 0.7351386587887544\n",
            "Update the best model to epoch 1\n",
            "epoch = 2\n",
            "validation recall @ top- 10 0.7708715147202543\n",
            "Update the best model to epoch 2\n",
            "epoch = 3\n",
            "validation recall @ top- 10 0.7896376400647074\n",
            "Update the best model to epoch 3\n",
            "epoch = 4\n",
            "validation recall @ top- 10 0.7971153736015517\n",
            "Update the best model to epoch 4\n",
            "epoch = 5\n",
            "validation recall @ top- 10 0.8031583698448137\n",
            "Update the best model to epoch 5\n",
            "epoch = 6\n",
            "validation recall @ top- 10 0.8069846623339478\n",
            "Update the best model to epoch 6\n",
            "epoch = 7\n",
            "validation recall @ top- 10 0.8056179039774692\n",
            "epoch = 8\n",
            "validation recall @ top- 10 0.8051980437284761\n",
            "epoch = 9\n",
            "validation recall @ top- 10 0.8067526137886466\n",
            "epoch = 10\n",
            "validation recall @ top- 10 0.8097728286672149\n",
            "Update the best model to epoch 10\n",
            "epoch = 11\n",
            "validation recall @ top- 10 0.8100733734335567\n",
            "Update the best model to epoch 11\n",
            "epoch = 12\n",
            "validation recall @ top- 10 0.8119575681204608\n",
            "Update the best model to epoch 12\n",
            "epoch = 13\n",
            "validation recall @ top- 10 0.8108364651700252\n",
            "epoch = 14\n",
            "validation recall @ top- 10 0.8102799024199078\n",
            "epoch = 15\n",
            "validation recall @ top- 10 0.8087337081278028\n",
            "epoch = 16\n",
            "validation recall @ top- 10 0.8094870598414676\n",
            "epoch = 17\n",
            "validation recall @ top- 10 0.8062238521372127\n",
            "[0.6044048484082241, 0.7351386587887544, 0.7708715147202543, 0.7896376400647074, 0.7971153736015517, 0.8031583698448137, 0.8069846623339478, 0.8056179039774692, 0.8051980437284761, 0.8067526137886466, 0.8097728286672149, 0.8100733734335567, 0.8119575681204608, 0.8108364651700252, 0.8102799024199078, 0.8087337081278028, 0.8094870598414676, 0.8062238521372127] 12\n",
            "\n",
            "Train model with KSI\n",
            "epoch = 0\n",
            "validation recall @ top- 10 0.8148472185408665\n",
            "Update the best model to epoch 0\n",
            "epoch = 1\n",
            "validation recall @ top- 10 0.8159741854478278\n",
            "Update the best model to epoch 1\n",
            "epoch = 2\n",
            "validation recall @ top- 10 0.8175181384128967\n",
            "Update the best model to epoch 2\n",
            "epoch = 3\n",
            "validation recall @ top- 10 0.8175836715079843\n",
            "Update the best model to epoch 3\n",
            "epoch = 4\n",
            "validation recall @ top- 10 0.8171208771813717\n",
            "epoch = 5\n",
            "validation recall @ top- 10 0.815820964977417\n",
            "epoch = 6\n",
            "validation recall @ top- 10 0.8145183393921027\n",
            "epoch = 7\n",
            "validation recall @ top- 10 0.8140329248516374\n",
            "epoch = 8\n",
            "validation recall @ top- 10 0.8119121036035504\n",
            "[0.8148472185408665, 0.8159741854478278, 0.8175181384128967, 0.8175836715079843, 0.8171208771813717, 0.815820964977417, 0.8145183393921027, 0.8140329248516374, 0.8119121036035504] 3\n"
          ]
        }
      ],
      "source": [
        "from training import trainmodel\n",
        "\n",
        "topk = 10\n",
        "max_epochs = 5000 # Default is 5000\n",
        "print(f\"max epochs = {max_epochs}\")\n",
        "\n",
        "model = CAML(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "model.cuda()\n",
        "\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "print(\"Train basemodel\")\n",
        "basemodel= trainmodel(model, 0, topk, max_epochs, batchtraining_data, batchval_data, wikivec, loss_function, optimizer)\n",
        "torch.save(basemodel, 'CAML_model')\n",
        "\n",
        "model = CAML(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "model.cuda()\n",
        "model.load_state_dict(basemodel)\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "print(\"\")\n",
        "print(\"Train model with KSI\")\n",
        "KSImodel= trainmodel(model, 1, topk, max_epochs, batchtraining_data, batchval_data, wikivec, loss_function, optimizer)\n",
        "torch.save(KSImodel, 'KSI_CAML_model')  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the trained models on the test dataset. The function `testmodel` can be found in `testing.py`."
      ],
      "metadata": {
        "id": "TeEmocpzaHc_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ3VaeGnunce",
        "outputId": "9c76a7fb-bb2f-46f4-c2b7-58478e95a44a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test CAML baseline\n",
            "Test KSI+CAML\n"
          ]
        }
      ],
      "source": [
        "from testing import testmodel\n",
        "\n",
        "\n",
        "print('Test CAML baseline')\n",
        "model1 = CAML(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "caml_loss, caml_recall, caml_mac_auc, caml_mic_auc, caml_mac_f1, caml_mic_f1 = testmodel(model1, basemodel, 0, batchtest_data, wikivec, topk)\n",
        "print('Test KSI+CAML')\n",
        "model2 = CAML(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "camlKSI_loss, camlKSI_recall, camlKSI_mac_auc, camlKSI_mic_auc, camlKSI_mac_f1, camlKSI_mic_f1 = testmodel(model2, KSImodel, 1, batchtest_data, wikivec, topk)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the total running time of this section."
      ],
      "metadata": {
        "id": "m3qBdL1saS9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop = timeit.default_timer()\n",
        "duration = str(datetime.timedelta(seconds=round(stop-start)))\n",
        "duration = duration.split(\":\")\n",
        "print(f'Running time of this section: {duration[0]}h {duration[1]}m {duration[2]}s') "
      ],
      "metadata": {
        "id": "bRG3E6bMnJuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3cd8ff5-c499-467b-bc52-ff40429da05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running time of this section: 0h 21m 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the performance metrics of the standalone CAML model and the CAML model with the KSI framework."
      ],
      "metadata": {
        "id": "ozo51c8MaYDG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "WctM9Bmjxj7q",
        "outputId": "9feac31e-028d-4388-a94d-ea2a0cec864f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Model  Macro_AUC  Micro_AUC  Macro_F1  Micro_F1   Loss  Recall@10\n",
              "0      CAML      0.854      0.978     0.281     0.658  0.033      0.808\n",
              "1  KSI+CAML      0.878      0.980     0.292     0.664  0.032      0.814"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53c81b93-bcbf-4026-86a1-f69a86bd86da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Macro_AUC</th>\n",
              "      <th>Micro_AUC</th>\n",
              "      <th>Macro_F1</th>\n",
              "      <th>Micro_F1</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Recall@10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CAML</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.281</td>\n",
              "      <td>0.658</td>\n",
              "      <td>0.033</td>\n",
              "      <td>0.808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KSI+CAML</td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.980</td>\n",
              "      <td>0.292</td>\n",
              "      <td>0.664</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.814</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53c81b93-bcbf-4026-86a1-f69a86bd86da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-53c81b93-bcbf-4026-86a1-f69a86bd86da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-53c81b93-bcbf-4026-86a1-f69a86bd86da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "result_caml = [['CAML',  \n",
        "                round(caml_mac_auc, 3), \n",
        "                round(caml_mic_auc, 3), \n",
        "                round(caml_mac_f1, 3), \n",
        "                round(caml_mic_f1, 3),\n",
        "                round(caml_loss, 3),\n",
        "                round(caml_recall, 3)], \n",
        "        ['KSI+CAML',  \n",
        "         round(camlKSI_mac_auc, 3), \n",
        "         round(camlKSI_mic_auc, 3), \n",
        "         round(camlKSI_mac_f1, 3), \n",
        "         round(camlKSI_mic_f1, 3),\n",
        "         round(camlKSI_loss, 3),\n",
        "         round(camlKSI_recall, 3)]]\n",
        "df_caml = pd.DataFrame(result_caml, columns=['Model', 'Macro_AUC', 'Micro_AUC', 'Macro_F1', 'Micro_F1', 'Loss', 'Recall@10'])\n",
        "df_caml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q3JjI9W5H7n"
      },
      "source": [
        "## 5.2 Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section compares the performance of the following models in the task of ICD-9 diagnosis code prediction from the clinical notes in MIMIC-III dataset:\n",
        "\n",
        "*   Standalone model of convolutional neural network (CNN).\n",
        "*   Convolutional neural network with the KSI framework (KSI+CNN).\n",
        "\n",
        "First, import the Python packages needed for this section."
      ],
      "metadata": {
        "id": "S4fjfyL-a5v9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMVm37jL5O1j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "torch.manual_seed(1)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record the start timestamp of this section to track the total running time of this section."
      ],
      "metadata": {
        "id": "8lr9g_ALc4mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = timeit.default_timer()"
      ],
      "metadata": {
        "id": "a7uLRxSEl3i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the standalone CNN model and the CNN model with the KSI framework."
      ],
      "metadata": {
        "id": "Frr5UJEldG9-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YewIyMJX3QGE"
      },
      "outputs": [],
      "source": [
        "Embeddingsize = 100\n",
        "hidden_dim = 200\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self, batch_size, vocab_size, tagset_size):\n",
        "        super(CNN, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.word_embeddings = nn.Embedding(vocab_size+1, Embeddingsize, padding_idx=0)\n",
        "        self.embed_drop = nn.Dropout(p=0.2)\n",
        "        \n",
        "        self.hidden2tag = nn.Linear(300, tagset_size)\n",
        "        \n",
        "        \n",
        "        self.convs1 = nn.Conv1d(Embeddingsize,100,3)\n",
        "        self.convs2 = nn.Conv1d(Embeddingsize,100,4)\n",
        "        self.convs3 = nn.Conv1d(Embeddingsize,100,5)\n",
        "        \n",
        "        \n",
        "        self.layer2 = nn.Linear(Embeddingsize, 1,bias=False)\n",
        "        self.embedding=nn.Linear(rvocsize,Embeddingsize)\n",
        "        self.vattention=nn.Linear(Embeddingsize,Embeddingsize)\n",
        "        \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "    \n",
        "    def forward(self, vec1, nvec, wiki, simlearning):\n",
        "       \n",
        "        thisembeddings=self.word_embeddings(vec1)\n",
        "        thisembeddings = self.embed_drop(thisembeddings)\n",
        "        thisembeddings=thisembeddings.transpose(1,2)\n",
        "        \n",
        "        output1=self.tanh(self.convs1(thisembeddings))\n",
        "        output1=nn.MaxPool1d(output1.size()[2])(output1)\n",
        "        \n",
        "        output2=self.tanh(self.convs2(thisembeddings))\n",
        "        output2=nn.MaxPool1d(output2.size()[2])(output2)\n",
        "        \n",
        "        output3=self.tanh(self.convs3(thisembeddings))\n",
        "        output3=nn.MaxPool1d(output3.size()[2])(output3)\n",
        "        \n",
        "        output4 = torch.cat([output1,output2,output3], 1).squeeze(2)\n",
        "        \n",
        "        if simlearning==1:\n",
        "            nvec=nvec.view(batchsize,1,-1)\n",
        "            nvec=nvec.expand(batchsize,wiki.size()[0],-1)\n",
        "            wiki=wiki.view(1,wiki.size()[0],-1)\n",
        "            wiki=wiki.expand(nvec.size()[0],wiki.size()[1],-1)\n",
        "            new=wiki*nvec\n",
        "            new=self.embedding(new)\n",
        "            vattention=self.sigmoid(self.vattention(new))\n",
        "            new=new*vattention\n",
        "            vec3=self.layer2(new)\n",
        "            vec3=vec3.view(batchsize,-1)\n",
        "        \n",
        "       \n",
        "        vec2 = self.hidden2tag(output4)\n",
        "        if simlearning==1:\n",
        "            tag_scores = self.sigmoid(vec2.detach()+vec3)\n",
        "        else:\n",
        "            tag_scores = self.sigmoid(vec2)\n",
        "        \n",
        "        \n",
        "        return tag_scores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the standalone CNN model and the CNN model with the KSI framework. The training will stop if the top-10 recall score does not improve on the validation dataset in the next 5 epochs. The function `trainmodel` can be found in `training.py`."
      ],
      "metadata": {
        "id": "hZLvzsNkdawY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltyopui83P0j",
        "outputId": "41a18ea9-66c1-4375-f9d6-b1627e0e5187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max epochs = 5000\n",
            "Train basemodel\n",
            "epoch = 0\n",
            "validation recall @ top- 10 0.435576072001294\n",
            "Update the best model to epoch 0\n",
            "epoch = 1\n",
            "validation recall @ top- 10 0.5295547700087251\n",
            "Update the best model to epoch 1\n",
            "epoch = 2\n",
            "validation recall @ top- 10 0.5793614431213167\n",
            "Update the best model to epoch 2\n",
            "epoch = 3\n",
            "validation recall @ top- 10 0.6133845415790744\n",
            "Update the best model to epoch 3\n",
            "epoch = 4\n",
            "validation recall @ top- 10 0.6379938584306174\n",
            "Update the best model to epoch 4\n",
            "epoch = 5\n",
            "validation recall @ top- 10 0.6691907628228477\n",
            "Update the best model to epoch 5\n",
            "epoch = 6\n",
            "validation recall @ top- 10 0.681347909553765\n",
            "Update the best model to epoch 6\n",
            "epoch = 7\n",
            "validation recall @ top- 10 0.6934263199017563\n",
            "Update the best model to epoch 7\n",
            "epoch = 8\n",
            "validation recall @ top- 10 0.7034733145177275\n",
            "Update the best model to epoch 8\n",
            "epoch = 9\n",
            "validation recall @ top- 10 0.7102572968458909\n",
            "Update the best model to epoch 9\n",
            "epoch = 10\n",
            "validation recall @ top- 10 0.7207585492306556\n",
            "Update the best model to epoch 10\n",
            "epoch = 11\n",
            "validation recall @ top- 10 0.7280679801337707\n",
            "Update the best model to epoch 11\n",
            "epoch = 12\n",
            "validation recall @ top- 10 0.733034467536074\n",
            "Update the best model to epoch 12\n",
            "epoch = 13\n",
            "validation recall @ top- 10 0.7382244416169105\n",
            "Update the best model to epoch 13\n",
            "epoch = 14\n",
            "validation recall @ top- 10 0.7407368003703669\n",
            "Update the best model to epoch 14\n",
            "epoch = 15\n",
            "validation recall @ top- 10 0.7441884278490034\n",
            "Update the best model to epoch 15\n",
            "epoch = 16\n",
            "validation recall @ top- 10 0.7489343008560962\n",
            "Update the best model to epoch 16\n",
            "epoch = 17\n",
            "validation recall @ top- 10 0.7514368980379081\n",
            "Update the best model to epoch 17\n",
            "epoch = 18\n",
            "validation recall @ top- 10 0.7554908157659127\n",
            "Update the best model to epoch 18\n",
            "epoch = 19\n",
            "validation recall @ top- 10 0.7537256492177045\n",
            "epoch = 20\n",
            "validation recall @ top- 10 0.7577932639665189\n",
            "Update the best model to epoch 20\n",
            "epoch = 21\n",
            "validation recall @ top- 10 0.7573848002441846\n",
            "epoch = 22\n",
            "validation recall @ top- 10 0.7588890439023118\n",
            "Update the best model to epoch 22\n",
            "epoch = 23\n",
            "validation recall @ top- 10 0.7568789804058829\n",
            "epoch = 24\n",
            "validation recall @ top- 10 0.758690439882824\n",
            "epoch = 25\n",
            "validation recall @ top- 10 0.7573379636729334\n",
            "epoch = 26\n",
            "validation recall @ top- 10 0.7591271716449687\n",
            "Update the best model to epoch 26\n",
            "epoch = 27\n",
            "validation recall @ top- 10 0.759016596107256\n",
            "epoch = 28\n",
            "validation recall @ top- 10 0.7572406790196521\n",
            "epoch = 29\n",
            "validation recall @ top- 10 0.7556544333298543\n",
            "epoch = 30\n",
            "validation recall @ top- 10 0.7578139162735431\n",
            "epoch = 31\n",
            "validation recall @ top- 10 0.7577008643066157\n",
            "[0.435576072001294, 0.5295547700087251, 0.5793614431213167, 0.6133845415790744, 0.6379938584306174, 0.6691907628228477, 0.681347909553765, 0.6934263199017563, 0.7034733145177275, 0.7102572968458909, 0.7207585492306556, 0.7280679801337707, 0.733034467536074, 0.7382244416169105, 0.7407368003703669, 0.7441884278490034, 0.7489343008560962, 0.7514368980379081, 0.7554908157659127, 0.7537256492177045, 0.7577932639665189, 0.7573848002441846, 0.7588890439023118, 0.7568789804058829, 0.758690439882824, 0.7573379636729334, 0.7591271716449687, 0.759016596107256, 0.7572406790196521, 0.7556544333298543, 0.7578139162735431, 0.7577008643066157] 26\n",
            "\n",
            "Train model with KSI\n",
            "epoch = 0\n",
            "validation recall @ top- 10 0.7718865785847925\n",
            "Update the best model to epoch 0\n",
            "epoch = 1\n",
            "validation recall @ top- 10 0.7743394108680232\n",
            "Update the best model to epoch 1\n",
            "epoch = 2\n",
            "validation recall @ top- 10 0.7787075102197302\n",
            "Update the best model to epoch 2\n",
            "epoch = 3\n",
            "validation recall @ top- 10 0.781707036457317\n",
            "Update the best model to epoch 3\n",
            "epoch = 4\n",
            "validation recall @ top- 10 0.7837981295263792\n",
            "Update the best model to epoch 4\n",
            "epoch = 5\n",
            "validation recall @ top- 10 0.785592144324698\n",
            "Update the best model to epoch 5\n",
            "epoch = 6\n",
            "validation recall @ top- 10 0.7842138205582045\n",
            "epoch = 7\n",
            "validation recall @ top- 10 0.7833409587990743\n",
            "epoch = 8\n",
            "validation recall @ top- 10 0.7817006261701485\n",
            "epoch = 9\n",
            "validation recall @ top- 10 0.7825025609797247\n",
            "epoch = 10\n",
            "validation recall @ top- 10 0.7791947871046104\n",
            "[0.7718865785847925, 0.7743394108680232, 0.7787075102197302, 0.781707036457317, 0.7837981295263792, 0.785592144324698, 0.7842138205582045, 0.7833409587990743, 0.7817006261701485, 0.7825025609797247, 0.7791947871046104] 5\n"
          ]
        }
      ],
      "source": [
        "from training import trainmodel\n",
        "\n",
        "\n",
        "topk = 10\n",
        "max_epochs = 5000 # Default is 5000\n",
        "print(f\"max epochs = {max_epochs}\")\n",
        "    \n",
        "model = CNN(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "model.cuda()\n",
        "\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "print(\"Train basemodel\")\n",
        "basemodel= trainmodel(model, 0, topk, max_epochs, batchtraining_data, batchval_data, wikivec, loss_function, optimizer)\n",
        "torch.save(basemodel, 'CNN_model')\n",
        "\n",
        "model = CNN(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "model.cuda()\n",
        "model.load_state_dict(basemodel)\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "print(\"\")\n",
        "print(\"Train model with KSI\")\n",
        "KSImodel= trainmodel(model, 1, topk, max_epochs, batchtraining_data, batchval_data, wikivec, loss_function, optimizer)\n",
        "torch.save(KSImodel, 'KSI_CNN_model') "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the trained models on the test dataset. The function `testmodel` can be found in `testing.py`."
      ],
      "metadata": {
        "id": "ij6RaFVBdx58"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsHlC0dM3Ppz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f315837e-ee7e-461c-9ed1-77c44a06c8ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test CNN baseline\n",
            "Test KSI+CNN\n"
          ]
        }
      ],
      "source": [
        "from testing import testmodel\n",
        "\n",
        "\n",
        "print('Test CNN baseline')\n",
        "model1 = CNN(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "cnn_loss, cnn_recall, cnn_mac_auc, cnn_mic_auc, cnn_mac_f1, cnn_mic_f1 = testmodel(model1, basemodel, 0, batchtest_data, wikivec, topk)\n",
        "print('Test KSI+CNN')\n",
        "model2 = CNN(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "cnnKSI_loss, cnnKSI_recall, cnnKSI_mac_auc, cnnKSI_mic_auc, cnnKSI_mac_f1, cnnKSI_mic_f1 = testmodel(model2, KSImodel, 1, batchtest_data, wikivec, topk)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the total running time of this section."
      ],
      "metadata": {
        "id": "dlPlAuIceGpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop = timeit.default_timer()\n",
        "duration = str(datetime.timedelta(seconds=round(stop-start)))\n",
        "duration = duration.split(\":\")\n",
        "print(f'Running time of this section: {duration[0]}h {duration[1]}m {duration[2]}s') "
      ],
      "metadata": {
        "id": "sCxo1NrZnVki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b30943-9c38-409c-ecd5-3214984e6424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running time of this section: 0h 21m 59s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the performance metrics of the standalone CNN model and the CNN model with the KSI framework."
      ],
      "metadata": {
        "id": "8Mhpi8pKeODV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wtI-cCHD0TGU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "173c368d-6457-4d63-e8f8-2c533084a685"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Model  Macro_AUC  Micro_AUC  Macro_F1  Micro_F1   Loss  Recall@10\n",
              "0      CNN      0.836      0.966     0.214     0.627  0.039      0.753\n",
              "1  KSI+CNN      0.871      0.973     0.242     0.643  0.037      0.779"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5167f8dd-b807-4897-9faa-46e26335ff6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Macro_AUC</th>\n",
              "      <th>Micro_AUC</th>\n",
              "      <th>Macro_F1</th>\n",
              "      <th>Micro_F1</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Recall@10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNN</td>\n",
              "      <td>0.836</td>\n",
              "      <td>0.966</td>\n",
              "      <td>0.214</td>\n",
              "      <td>0.627</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KSI+CNN</td>\n",
              "      <td>0.871</td>\n",
              "      <td>0.973</td>\n",
              "      <td>0.242</td>\n",
              "      <td>0.643</td>\n",
              "      <td>0.037</td>\n",
              "      <td>0.779</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5167f8dd-b807-4897-9faa-46e26335ff6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5167f8dd-b807-4897-9faa-46e26335ff6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5167f8dd-b807-4897-9faa-46e26335ff6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "result_cnn = [['CNN',  \n",
        "               round(cnn_mac_auc, 3), \n",
        "               round(cnn_mic_auc, 3), \n",
        "               round(cnn_mac_f1, 3), \n",
        "               round(cnn_mic_f1, 3),\n",
        "               round(cnn_loss, 3),\n",
        "               round(cnn_recall, 3)], \n",
        "        ['KSI+CNN',  \n",
        "         round(cnnKSI_mac_auc, 3), \n",
        "         round(cnnKSI_mic_auc, 3), \n",
        "         round(cnnKSI_mac_f1, 3), \n",
        "         round(cnnKSI_mic_f1, 3),\n",
        "         round(cnnKSI_loss, 3),\n",
        "         round(cnnKSI_recall, 3)]]\n",
        "df_cnn = pd.DataFrame(result_cnn, columns=['Model', 'Macro_AUC', 'Micro_AUC', 'Macro_F1', 'Micro_F1', 'Loss', 'Recall@10',])\n",
        "df_cnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkDnKdxe59rK"
      },
      "source": [
        "## 5.3 Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section compares the performance of the following models in the task of ICD-9 diagnosis code prediction from the clinical notes in MIMIC-III dataset:\n",
        "\n",
        "*   Standalone model of recurrent neural network (RNN).\n",
        "*   Recurrent neural network with the KSI framework (KSI+RNN).\n",
        "\n",
        "First, import the Python packages needed for this section."
      ],
      "metadata": {
        "id": "E_6j6779bORM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X66ixrUQ6E4i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "torch.manual_seed(1)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record the start timestamp of this section to track the total running time of this section."
      ],
      "metadata": {
        "id": "Tqphz5OVc6IV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = timeit.default_timer()"
      ],
      "metadata": {
        "id": "eb20LmaWmGHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the standalone RNN model and the RNN model with the KSI framework."
      ],
      "metadata": {
        "id": "oN2OxP8NdK40"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqoAFdgx4v9a"
      },
      "outputs": [],
      "source": [
        "Embeddingsize = 100\n",
        "hidden_dim = 200\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, batch_size, vocab_size, tagset_size):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.word_embeddings = nn.Embedding(vocab_size+1, Embeddingsize, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(Embeddingsize, hidden_dim)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "        self.hidden = self.init_hidden()\n",
        "        \n",
        "        \n",
        "        self.layer2 = nn.Linear(Embeddingsize, 1,bias=False)\n",
        "        self.embedding=nn.Linear(rvocsize,Embeddingsize)\n",
        "        self.vattention=nn.Linear(Embeddingsize,Embeddingsize,bias=False)\n",
        "        \n",
        "        self.softmax = nn.Softmax()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.embed_drop = nn.Dropout(p=0.2)\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        return (autograd.Variable(torch.zeros(1, batchsize, self.hidden_dim).cuda()),\n",
        "                autograd.Variable(torch.zeros(1, batchsize, self.hidden_dim)).cuda())\n",
        "\n",
        "    \n",
        "    def forward(self, vec1, nvec, wiki, simlearning):\n",
        "      \n",
        "        thisembeddings=self.word_embeddings(vec1).transpose(0,1)\n",
        "        thisembeddings = self.embed_drop(thisembeddings)\n",
        "       \n",
        "        if simlearning==1:\n",
        "            nvec=nvec.view(batchsize,1,-1)\n",
        "            nvec=nvec.expand(batchsize,wiki.size()[0],-1)\n",
        "            wiki=wiki.view(1,wiki.size()[0],-1)\n",
        "            wiki=wiki.expand(nvec.size()[0],wiki.size()[1],-1)\n",
        "            new=wiki*nvec\n",
        "            new=self.embedding(new)\n",
        "            vattention=self.sigmoid(self.vattention(new))\n",
        "            new=new*vattention\n",
        "            vec3=self.layer2(new)\n",
        "            vec3=vec3.view(batchsize,-1)\n",
        "        \n",
        "        \n",
        "        \n",
        "        lstm_out, self.hidden = self.lstm(thisembeddings, self.hidden)\n",
        "        \n",
        "        lstm_out=lstm_out.transpose(0,2).transpose(0,1)\n",
        "        \n",
        "        output1=nn.MaxPool1d(lstm_out.size()[2])(lstm_out).view(batchsize,-1)\n",
        "        \n",
        "        vec2 = self.hidden2tag(output1)\n",
        "        if simlearning==1:\n",
        "            tag_scores = self.sigmoid(vec2.detach()+vec3)\n",
        "        else:\n",
        "            tag_scores = self.sigmoid(vec2)\n",
        "        \n",
        "        \n",
        "        return tag_scores "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the standalone RNN model and the RNN model with the KSI framework. The training will stop if the top-10 recall score does not improve on the validation dataset in the next 5 epochs. The function `trainrnnmodel` can be found in `training.py`."
      ],
      "metadata": {
        "id": "fbEbyFMidhl3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfQfhEY64vzW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4c4613a-4e62-4603-e5a7-1fcebb61e931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max epochs = 5000\n",
            "Train basemodel\n",
            "epoch = 0\n",
            "validation recall @ top- 10 0.42907168088451775\n",
            "Update the best model to epoch 0\n",
            "epoch = 1\n",
            "validation recall @ top- 10 0.5000333124844674\n",
            "Update the best model to epoch 1\n",
            "epoch = 2\n",
            "validation recall @ top- 10 0.5471905671863649\n",
            "Update the best model to epoch 2\n",
            "epoch = 3\n",
            "validation recall @ top- 10 0.5752512430977793\n",
            "Update the best model to epoch 3\n",
            "epoch = 4\n",
            "validation recall @ top- 10 0.6096955982153277\n",
            "Update the best model to epoch 4\n",
            "epoch = 5\n",
            "validation recall @ top- 10 0.6308416103902218\n",
            "Update the best model to epoch 5\n",
            "epoch = 6\n",
            "validation recall @ top- 10 0.6511362851503391\n",
            "Update the best model to epoch 6\n",
            "epoch = 7\n",
            "validation recall @ top- 10 0.6686542080911598\n",
            "Update the best model to epoch 7\n",
            "epoch = 8\n",
            "validation recall @ top- 10 0.685425504729022\n",
            "Update the best model to epoch 8\n",
            "epoch = 9\n",
            "validation recall @ top- 10 0.6948810973320029\n",
            "Update the best model to epoch 9\n",
            "epoch = 10\n",
            "validation recall @ top- 10 0.7085747024482247\n",
            "Update the best model to epoch 10\n",
            "epoch = 11\n",
            "validation recall @ top- 10 0.7190966658910583\n",
            "Update the best model to epoch 11\n",
            "epoch = 12\n",
            "validation recall @ top- 10 0.7228397115765063\n",
            "Update the best model to epoch 12\n",
            "epoch = 13\n",
            "validation recall @ top- 10 0.7301364762399277\n",
            "Update the best model to epoch 13\n",
            "epoch = 14\n",
            "validation recall @ top- 10 0.7317604788061133\n",
            "Update the best model to epoch 14\n",
            "epoch = 15\n",
            "validation recall @ top- 10 0.7378357223538403\n",
            "Update the best model to epoch 15\n",
            "epoch = 16\n",
            "validation recall @ top- 10 0.7400763027438104\n",
            "Update the best model to epoch 16\n",
            "epoch = 17\n",
            "validation recall @ top- 10 0.7413407794395444\n",
            "Update the best model to epoch 17\n",
            "epoch = 18\n",
            "validation recall @ top- 10 0.7446393473630326\n",
            "Update the best model to epoch 18\n",
            "epoch = 19\n",
            "validation recall @ top- 10 0.7482550660227777\n",
            "Update the best model to epoch 19\n",
            "epoch = 20\n",
            "validation recall @ top- 10 0.7487245313777922\n",
            "Update the best model to epoch 20\n",
            "epoch = 21\n",
            "validation recall @ top- 10 0.7530766997883954\n",
            "Update the best model to epoch 21\n",
            "epoch = 22\n",
            "validation recall @ top- 10 0.7499493094030312\n",
            "epoch = 23\n",
            "validation recall @ top- 10 0.7527787370343136\n",
            "epoch = 24\n",
            "validation recall @ top- 10 0.7547958401984595\n",
            "Update the best model to epoch 24\n",
            "epoch = 25\n",
            "validation recall @ top- 10 0.7531841030929262\n",
            "epoch = 26\n",
            "validation recall @ top- 10 0.7546549058297516\n",
            "epoch = 27\n",
            "validation recall @ top- 10 0.751383879026223\n",
            "epoch = 28\n",
            "validation recall @ top- 10 0.7532464591029683\n",
            "epoch = 29\n",
            "validation recall @ top- 10 0.7525840809727551\n",
            "[0.42907168088451775, 0.5000333124844674, 0.5471905671863649, 0.5752512430977793, 0.6096955982153277, 0.6308416103902218, 0.6511362851503391, 0.6686542080911598, 0.685425504729022, 0.6948810973320029, 0.7085747024482247, 0.7190966658910583, 0.7228397115765063, 0.7301364762399277, 0.7317604788061133, 0.7378357223538403, 0.7400763027438104, 0.7413407794395444, 0.7446393473630326, 0.7482550660227777, 0.7487245313777922, 0.7530766997883954, 0.7499493094030312, 0.7527787370343136, 0.7547958401984595, 0.7531841030929262, 0.7546549058297516, 0.751383879026223, 0.7532464591029683, 0.7525840809727551] 24\n",
            "\n",
            "Train model with KSI\n",
            "epoch = 0\n",
            "validation recall @ top- 10 0.7788642129104534\n",
            "Update the best model to epoch 0\n",
            "epoch = 1\n",
            "validation recall @ top- 10 0.7849038520674628\n",
            "Update the best model to epoch 1\n",
            "epoch = 2\n",
            "validation recall @ top- 10 0.7885388821808801\n",
            "Update the best model to epoch 2\n",
            "epoch = 3\n",
            "validation recall @ top- 10 0.7888129141420435\n",
            "Update the best model to epoch 3\n",
            "epoch = 4\n",
            "validation recall @ top- 10 0.7868366390218821\n",
            "epoch = 5\n",
            "validation recall @ top- 10 0.7864098739163096\n",
            "epoch = 6\n",
            "validation recall @ top- 10 0.7843875169234703\n",
            "epoch = 7\n",
            "validation recall @ top- 10 0.7822528825227657\n",
            "epoch = 8\n",
            "validation recall @ top- 10 0.7778421601216052\n",
            "[0.7788642129104534, 0.7849038520674628, 0.7885388821808801, 0.7888129141420435, 0.7868366390218821, 0.7864098739163096, 0.7843875169234703, 0.7822528825227657, 0.7778421601216052] 3\n"
          ]
        }
      ],
      "source": [
        "from training import trainrnnmodel\n",
        "\n",
        "\n",
        "topk = 10\n",
        "max_epochs = 5000 # Default is 5000\n",
        "print(f\"max epochs = {max_epochs}\")\n",
        "    \n",
        "model = LSTM(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "model.cuda()\n",
        "\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "print(\"Train basemodel\")\n",
        "basemodel= trainrnnmodel(model, 0, topk, max_epochs, batchtraining_data, batchval_data, wikivec, loss_function, optimizer)\n",
        "torch.save(basemodel, 'RNN_model')\n",
        "\n",
        "model = LSTM(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "model.cuda()\n",
        "model.load_state_dict(basemodel)\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "print(\"\")\n",
        "print(\"Train model with KSI\")\n",
        "KSImodel= trainrnnmodel(model, 1, topk, max_epochs, batchtraining_data, batchval_data, wikivec, loss_function, optimizer)\n",
        "torch.save(KSImodel, 'KSI_RNN_model')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the trained models on the test dataset. The function `testrnnmodel` can be found in `testing.py`. "
      ],
      "metadata": {
        "id": "U1k37mrxd1-N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiC8A_fe4vmr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f789af-d5e2-4769-bdf3-ae7ab0a31367"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RNN baseline\n",
            "Test KSI+RNN\n"
          ]
        }
      ],
      "source": [
        "from testing import testrnnmodel\n",
        "\n",
        "\n",
        "print('Test RNN baseline')\n",
        "model1 = LSTM(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "lstm_loss, lstm_recall, lstm_mac_auc, lstm_mic_auc, lstm_mac_f1, lstm_mic_f1 = testrnnmodel(model1, basemodel, 0, batchtest_data, wikivec, topk)\n",
        "print('Test KSI+RNN')\n",
        "model2 = LSTM(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "lstmKSI_loss, lstmKSI_recall, lstmKSI_mac_auc, lstmKSI_mic_auc, lstmKSI_mac_f1, lstmKSI_mic_f1 = testrnnmodel(model2, KSImodel, 1, batchtest_data, wikivec, topk) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the total running time of this section."
      ],
      "metadata": {
        "id": "qV0uN41QeIbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop = timeit.default_timer()\n",
        "duration = str(datetime.timedelta(seconds=round(stop-start)))\n",
        "duration = duration.split(\":\")\n",
        "print(f'Running time of this section: {duration[0]}h {duration[1]}m {duration[2]}s') "
      ],
      "metadata": {
        "id": "H2euW6N5nYOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac759d9-c64f-4d17-bd4f-91c85c79d411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running time of this section: 0h 39m 16s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the performance metrics of the standalone RNN model and the RNN model with the KSI framework."
      ],
      "metadata": {
        "id": "rnt7JtR8eRUy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yyTdmPHX4CHd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "5d78946b-e950-4724-a7aa-8c85b62521af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Model  Macro_AUC  Micro_AUC  Macro_F1  Micro_F1   Loss  Recall@10\n",
              "0      RNN      0.843      0.970     0.208     0.647  0.034      0.768\n",
              "1  KSI+RNN      0.873      0.976     0.249     0.657  0.032      0.792"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-244a3827-f01b-4dd3-80e9-866d5d1fd038\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Macro_AUC</th>\n",
              "      <th>Micro_AUC</th>\n",
              "      <th>Macro_F1</th>\n",
              "      <th>Micro_F1</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Recall@10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RNN</td>\n",
              "      <td>0.843</td>\n",
              "      <td>0.970</td>\n",
              "      <td>0.208</td>\n",
              "      <td>0.647</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KSI+RNN</td>\n",
              "      <td>0.873</td>\n",
              "      <td>0.976</td>\n",
              "      <td>0.249</td>\n",
              "      <td>0.657</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-244a3827-f01b-4dd3-80e9-866d5d1fd038')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-244a3827-f01b-4dd3-80e9-866d5d1fd038 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-244a3827-f01b-4dd3-80e9-866d5d1fd038');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "result_lstm = [['RNN', \n",
        "                round(lstm_mac_auc, 3), \n",
        "                round(lstm_mic_auc, 3), \n",
        "                round(lstm_mac_f1, 3), \n",
        "                round(lstm_mic_f1, 3),\n",
        "                round(lstm_loss, 3),\n",
        "                round(lstm_recall, 3)], \n",
        "        ['KSI+RNN',  \n",
        "         round(lstmKSI_mac_auc, 3), \n",
        "         round(lstmKSI_mic_auc, 3), \n",
        "         round(lstmKSI_mac_f1, 3), \n",
        "         round(lstmKSI_mic_f1, 3),\n",
        "         round(lstmKSI_loss, 3), \n",
        "         round(lstmKSI_recall, 3)]]\n",
        "df_lstm = pd.DataFrame(result_lstm, columns=['Model', 'Macro_AUC', 'Micro_AUC', 'Macro_F1', 'Micro_F1', 'Loss', 'Recall@10'])\n",
        "df_lstm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naBdrr6p6Qd3"
      },
      "source": [
        "## 5.4 Recurrent Neural Network with Attention (RNNatt)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section compares the performance of the following models in the task of ICD-9 diagnosis code prediction from the clinical notes in MIMIC-III dataset:\n",
        "\n",
        "*   Standalone model of recurrent neural network with attention (RNNatt).\n",
        "*   Recurrent neural network with attention and the KSI framework (KSI+RNNatt).\n",
        "\n",
        "First, import the Python packages needed for this section."
      ],
      "metadata": {
        "id": "W56eBHZocvBj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AI_2DjA6XNX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "torch.manual_seed(1)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import f1_score\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Record the start timestamp of this section to track the total running time of this section."
      ],
      "metadata": {
        "id": "VHO7QrMec7al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = timeit.default_timer()"
      ],
      "metadata": {
        "id": "vS69PS2gmRsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the standalone RNN model with attention and the RNN model with attention and the KSI framework."
      ],
      "metadata": {
        "id": "aOSEQuLTdRFl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWX-Pan9AyTt"
      },
      "outputs": [],
      "source": [
        "Embeddingsize = 100\n",
        "hidden_dim = 200\n",
        "\n",
        "class LSTMattn(nn.Module):\n",
        "\n",
        "    def __init__(self, batch_size, vocab_size, tagset_size):\n",
        "        super(LSTMattn, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.word_embeddings = nn.Embedding(vocab_size+1, Embeddingsize, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(Embeddingsize, hidden_dim)\n",
        "        self.hidden = self.init_hidden()\n",
        "        \n",
        "        self.H=nn.Linear(hidden_dim, tagset_size )  \n",
        "        self.final = nn.Linear(hidden_dim, tagset_size)\n",
        "        \n",
        "        self.layer2 = nn.Linear(Embeddingsize, 1,bias=False)\n",
        "        self.embedding=nn.Linear(rvocsize,Embeddingsize)\n",
        "        self.vattention=nn.Linear(Embeddingsize,Embeddingsize,bias=False)\n",
        "        \n",
        "        self.softmax = nn.Softmax()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.embed_drop = nn.Dropout(p=0.2)\n",
        "    \n",
        "    def init_hidden(self):\n",
        "        return (autograd.Variable(torch.zeros(1, batchsize, self.hidden_dim).cuda()),\n",
        "                autograd.Variable(torch.zeros(1, batchsize, self.hidden_dim)).cuda())\n",
        "\n",
        "    \n",
        "    def forward(self, vec1, nvec, wiki, simlearning):\n",
        "        \n",
        "        \n",
        "        thisembeddings=self.word_embeddings(vec1).transpose(0,1)\n",
        "        thisembeddings = self.embed_drop(thisembeddings)\n",
        "        \n",
        "        \n",
        "        if simlearning==1:\n",
        "            nvec=nvec.view(batchsize,1,-1)\n",
        "            nvec=nvec.expand(batchsize,wiki.size()[0],-1)\n",
        "            wiki=wiki.view(1,wiki.size()[0],-1)\n",
        "            wiki=wiki.expand(nvec.size()[0],wiki.size()[1],-1)\n",
        "            new=wiki*nvec\n",
        "            new=self.embedding(new)\n",
        "            vattention=self.sigmoid(self.vattention(new))\n",
        "            new=new*vattention\n",
        "            vec3=self.layer2(new)\n",
        "            vec3=vec3.view(batchsize,-1)\n",
        "        \n",
        "        \n",
        "        lstm_out, self.hidden = self.lstm(\n",
        "            thisembeddings, self.hidden)\n",
        "        \n",
        "        \n",
        "        \n",
        "        lstm_out=lstm_out.transpose(0,1)\n",
        "\n",
        "        alpha=self.H.weight.matmul(lstm_out.transpose(1,2))\n",
        "        alpha=F.softmax(alpha, dim=2)\n",
        "        \n",
        "        m=alpha.matmul(lstm_out)\n",
        "        \n",
        "        myfinal=self.final.weight.mul(m).sum(dim=2).add(self.final.bias)\n",
        "        \n",
        "        \n",
        "        if simlearning==1:\n",
        "            tag_scores = self.sigmoid(myfinal.detach()+vec3)\n",
        "        else:\n",
        "            tag_scores = self.sigmoid(myfinal)\n",
        "                \n",
        "        return tag_scores  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the standalone RNN model with attention and the RNN model with attention and the KSI framework. The training will stop if the top-10 recall score does not improve on the validation dataset in the next 5 epochs. The function `trainrnnmodel` can be found in `training.py`."
      ],
      "metadata": {
        "id": "OWXerBIedn2C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_vuC0SQAyMX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9591a341-f11c-4244-969d-0ae9ba5c43ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train basemodel\n",
            "epoch = 0\n",
            "validation recall @ top- 10 0.3796880833045024\n",
            "Update the best model to epoch 0\n",
            "epoch = 1\n",
            "validation recall @ top- 10 0.511078002036114\n",
            "Update the best model to epoch 1\n",
            "epoch = 2\n",
            "validation recall @ top- 10 0.6083505897830405\n",
            "Update the best model to epoch 2\n",
            "epoch = 3\n",
            "validation recall @ top- 10 0.6578323770023232\n",
            "Update the best model to epoch 3\n",
            "epoch = 4\n",
            "validation recall @ top- 10 0.6940694854775656\n",
            "Update the best model to epoch 4\n",
            "epoch = 5\n",
            "validation recall @ top- 10 0.7134766580187625\n",
            "Update the best model to epoch 5\n",
            "epoch = 6\n",
            "validation recall @ top- 10 0.7351077450246006\n",
            "Update the best model to epoch 6\n",
            "epoch = 7\n",
            "validation recall @ top- 10 0.7497311047325111\n",
            "Update the best model to epoch 7\n",
            "epoch = 8\n",
            "validation recall @ top- 10 0.7638417743842686\n",
            "Update the best model to epoch 8\n",
            "epoch = 9\n",
            "validation recall @ top- 10 0.7714110540940694\n",
            "Update the best model to epoch 9\n",
            "epoch = 10\n",
            "validation recall @ top- 10 0.774969991821008\n",
            "Update the best model to epoch 10\n",
            "epoch = 11\n",
            "validation recall @ top- 10 0.7780937672406609\n",
            "Update the best model to epoch 11\n",
            "epoch = 12\n",
            "validation recall @ top- 10 0.7796899274183245\n",
            "Update the best model to epoch 12\n",
            "epoch = 13\n",
            "validation recall @ top- 10 0.7846627915341744\n",
            "Update the best model to epoch 13\n",
            "epoch = 14\n",
            "validation recall @ top- 10 0.7869448535873622\n",
            "Update the best model to epoch 14\n",
            "epoch = 15\n",
            "validation recall @ top- 10 0.7907586907123316\n",
            "Update the best model to epoch 15\n",
            "epoch = 16\n",
            "validation recall @ top- 10 0.792178180238803\n",
            "Update the best model to epoch 16\n",
            "epoch = 17\n",
            "validation recall @ top- 10 0.7932546158453375\n",
            "Update the best model to epoch 17\n",
            "epoch = 18\n",
            "validation recall @ top- 10 0.7934719942204929\n",
            "Update the best model to epoch 18\n",
            "epoch = 19\n",
            "validation recall @ top- 10 0.7941044240549177\n",
            "Update the best model to epoch 19\n",
            "epoch = 20\n",
            "validation recall @ top- 10 0.7947282970816131\n",
            "Update the best model to epoch 20\n",
            "epoch = 21\n",
            "validation recall @ top- 10 0.7948295775778953\n",
            "Update the best model to epoch 21\n",
            "epoch = 22\n",
            "validation recall @ top- 10 0.7952666260762805\n",
            "Update the best model to epoch 22\n",
            "epoch = 23\n",
            "validation recall @ top- 10 0.7964260394771565\n",
            "Update the best model to epoch 23\n",
            "epoch = 24\n",
            "validation recall @ top- 10 0.7950298683334015\n",
            "epoch = 25\n",
            "validation recall @ top- 10 0.7941664522547107\n",
            "epoch = 26\n",
            "validation recall @ top- 10 0.7942662693236179\n",
            "epoch = 27\n",
            "validation recall @ top- 10 0.7931340328340216\n",
            "epoch = 28\n",
            "validation recall @ top- 10 0.7920185769582095\n",
            "[0.3796880833045024, 0.511078002036114, 0.6083505897830405, 0.6578323770023232, 0.6940694854775656, 0.7134766580187625, 0.7351077450246006, 0.7497311047325111, 0.7638417743842686, 0.7714110540940694, 0.774969991821008, 0.7780937672406609, 0.7796899274183245, 0.7846627915341744, 0.7869448535873622, 0.7907586907123316, 0.792178180238803, 0.7932546158453375, 0.7934719942204929, 0.7941044240549177, 0.7947282970816131, 0.7948295775778953, 0.7952666260762805, 0.7964260394771565, 0.7950298683334015, 0.7941664522547107, 0.7942662693236179, 0.7931340328340216, 0.7920185769582095] 23\n",
            "\n",
            "Train model with KSI\n",
            "epoch = 0\n",
            "validation recall @ top- 10 0.8044524504890043\n",
            "Update the best model to epoch 0\n",
            "epoch = 1\n",
            "validation recall @ top- 10 0.8077519626638417\n",
            "Update the best model to epoch 1\n",
            "epoch = 2\n",
            "validation recall @ top- 10 0.8085632619642344\n",
            "Update the best model to epoch 2\n",
            "epoch = 3\n",
            "validation recall @ top- 10 0.8090127823320602\n",
            "Update the best model to epoch 3\n",
            "epoch = 4\n",
            "validation recall @ top- 10 0.8099837960734994\n",
            "Update the best model to epoch 4\n",
            "epoch = 5\n",
            "validation recall @ top- 10 0.8105395280967576\n",
            "Update the best model to epoch 5\n",
            "epoch = 6\n",
            "validation recall @ top- 10 0.8083821146945708\n",
            "epoch = 7\n",
            "validation recall @ top- 10 0.8055942590181013\n",
            "epoch = 8\n",
            "validation recall @ top- 10 0.7957969225068804\n",
            "epoch = 9\n",
            "validation recall @ top- 10 0.8000810904014514\n",
            "epoch = 10\n",
            "validation recall @ top- 10 0.8011435031205949\n",
            "[0.8044524504890043, 0.8077519626638417, 0.8085632619642344, 0.8090127823320602, 0.8099837960734994, 0.8105395280967576, 0.8083821146945708, 0.8055942590181013, 0.7957969225068804, 0.8000810904014514, 0.8011435031205949] 5\n"
          ]
        }
      ],
      "source": [
        "from training import trainrnnmodel\n",
        "\n",
        "\n",
        "topk = 10\n",
        "max_epochs = 5000 # Default is 5000\n",
        "    \n",
        "model = LSTMattn(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "model.cuda()\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "print(\"Train basemodel\")\n",
        "basemodel= trainrnnmodel(model, 0, topk, max_epochs, batchtraining_data, batchval_data, wikivec, loss_function, optimizer)\n",
        "torch.save(basemodel, 'RNNattn_model')\n",
        "\n",
        "model = LSTMattn(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "model.cuda()\n",
        "model.load_state_dict(basemodel)\n",
        "loss_function = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "print(\"\")\n",
        "print(\"Train model with KSI\")\n",
        "KSImodel= trainrnnmodel(model, 1, topk, max_epochs, batchtraining_data, batchval_data, wikivec, loss_function, optimizer)\n",
        "torch.save(KSImodel, 'KSI_RNNattn_model')  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the trained models on the test dataset. The function `testrnnmodel` can be found in `testing.py`."
      ],
      "metadata": {
        "id": "Eax5gl3td404"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K38RNna0AyC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0058eee1-1317-4005-d4f7-a56e57c181dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RNNatt baseline\n",
            "Test KSI+RNNatt\n"
          ]
        }
      ],
      "source": [
        "from testing import testrnnmodel\n",
        "\n",
        "\n",
        "print('Test RNNatt baseline')\n",
        "model1 = LSTMattn(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "lstmatt_loss, lstmatt_recall, lstmatt_mac_auc, lstmatt_mic_auc, lstmatt_mac_f1, lstmatt_mic_f1 = testrnnmodel(model1, basemodel, 0, batchtest_data, wikivec, topk)\n",
        "print('Test KSI+RNNatt')\n",
        "model2 = LSTMattn(batchsize, len(word_to_ix), len(label_to_ix))\n",
        "lstmattKSI_loss, lstmattKSI_recall, lstmattKSI_mac_auc, lstmattKSI_mic_auc, lstmattKSI_mac_f1, lstmattKSI_mic_f1 = testrnnmodel(model2, KSImodel, 1, batchtest_data, wikivec, topk)  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the total running time of this section."
      ],
      "metadata": {
        "id": "wnebhUJOeJ1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop = timeit.default_timer()\n",
        "duration = str(datetime.timedelta(seconds=round(stop-start)))\n",
        "duration = duration.split(\":\")\n",
        "print(f'Running time of this section: {duration[0]}h {duration[1]}m {duration[2]}s') "
      ],
      "metadata": {
        "id": "xjUvLRlEna0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34eda29a-35dd-4e82-842b-47b9b8ccdc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running time of this section: 0h 47m 09s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the performance metrics of the standalone RNN model with attention and the RNN model with attention and the KSI framework."
      ],
      "metadata": {
        "id": "416qvXm4eUZO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "64QNeZ_n5Qzo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "740bf20f-bef1-4408-c1ba-980b4a573476"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Model  Macro_AUC  Micro_AUC  Macro_F1  Micro_F1   Loss  Recall@10\n",
              "0      RNNatt      0.843      0.974     0.250     0.650  0.034      0.793\n",
              "1  KSI+RNNatt      0.885      0.978     0.293     0.664  0.032      0.807"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c43bded4-9431-4593-85b0-76a5ffd3e7a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Macro_AUC</th>\n",
              "      <th>Micro_AUC</th>\n",
              "      <th>Macro_F1</th>\n",
              "      <th>Micro_F1</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Recall@10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RNNatt</td>\n",
              "      <td>0.843</td>\n",
              "      <td>0.974</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KSI+RNNatt</td>\n",
              "      <td>0.885</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.293</td>\n",
              "      <td>0.664</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.807</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c43bded4-9431-4593-85b0-76a5ffd3e7a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c43bded4-9431-4593-85b0-76a5ffd3e7a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c43bded4-9431-4593-85b0-76a5ffd3e7a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "result_lstmatt = [['RNNatt', \n",
        "                   round(lstmatt_mac_auc, 3), \n",
        "                   round(lstmatt_mic_auc, 3), \n",
        "                   round(lstmatt_mac_f1, 3), \n",
        "                   round(lstmatt_mic_f1, 3),\n",
        "                   round(lstmatt_loss, 3),\n",
        "                   round(lstmatt_recall, 3)], \n",
        "        ['KSI+RNNatt', \n",
        "         round(lstmattKSI_mac_auc, 3), \n",
        "         round(lstmattKSI_mic_auc, 3), \n",
        "         round(lstmattKSI_mac_f1, 3), \n",
        "         round(lstmattKSI_mic_f1, 3),\n",
        "         round(lstmattKSI_loss, 3), \n",
        "         round(lstmattKSI_recall, 3)]]\n",
        "df_lstmatt = pd.DataFrame(result_lstmatt, columns=['Model', 'Macro_AUC', 'Micro_AUC', 'Macro_F1', 'Micro_F1', 'Loss', 'Recall@10'])\n",
        "df_lstmatt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X1UJ2A35_B6"
      },
      "source": [
        "# 6 Performance Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following tables shows the performance metrics of the selected standalone baseline models and the baseline models with the KSI framework."
      ],
      "metadata": {
        "id": "jT9xh3xcf38C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "k4hGiRvN6CJy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "94592e51-99d4-43d3-9b0d-09bd145e6990"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Model  Macro_AUC  Micro_AUC  Macro_F1  Micro_F1   Loss  Recall@10\n",
              "0         RNN      0.843      0.970     0.208     0.647  0.034      0.768\n",
              "1     KSI+RNN      0.873      0.976     0.249     0.657  0.032      0.792\n",
              "0      RNNatt      0.843      0.974     0.250     0.650  0.034      0.793\n",
              "1  KSI+RNNatt      0.885      0.978     0.293     0.664  0.032      0.807\n",
              "0         CNN      0.836      0.966     0.214     0.627  0.039      0.753\n",
              "1     KSI+CNN      0.871      0.973     0.242     0.643  0.037      0.779\n",
              "0        CAML      0.854      0.978     0.281     0.658  0.033      0.808\n",
              "1    KSI+CAML      0.878      0.980     0.292     0.664  0.032      0.814"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b59fe886-c28e-4617-9d9c-920a41291400\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Macro_AUC</th>\n",
              "      <th>Micro_AUC</th>\n",
              "      <th>Macro_F1</th>\n",
              "      <th>Micro_F1</th>\n",
              "      <th>Loss</th>\n",
              "      <th>Recall@10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RNN</td>\n",
              "      <td>0.843</td>\n",
              "      <td>0.970</td>\n",
              "      <td>0.208</td>\n",
              "      <td>0.647</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KSI+RNN</td>\n",
              "      <td>0.873</td>\n",
              "      <td>0.976</td>\n",
              "      <td>0.249</td>\n",
              "      <td>0.657</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RNNatt</td>\n",
              "      <td>0.843</td>\n",
              "      <td>0.974</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.034</td>\n",
              "      <td>0.793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KSI+RNNatt</td>\n",
              "      <td>0.885</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.293</td>\n",
              "      <td>0.664</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CNN</td>\n",
              "      <td>0.836</td>\n",
              "      <td>0.966</td>\n",
              "      <td>0.214</td>\n",
              "      <td>0.627</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KSI+CNN</td>\n",
              "      <td>0.871</td>\n",
              "      <td>0.973</td>\n",
              "      <td>0.242</td>\n",
              "      <td>0.643</td>\n",
              "      <td>0.037</td>\n",
              "      <td>0.779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CAML</td>\n",
              "      <td>0.854</td>\n",
              "      <td>0.978</td>\n",
              "      <td>0.281</td>\n",
              "      <td>0.658</td>\n",
              "      <td>0.033</td>\n",
              "      <td>0.808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KSI+CAML</td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.980</td>\n",
              "      <td>0.292</td>\n",
              "      <td>0.664</td>\n",
              "      <td>0.032</td>\n",
              "      <td>0.814</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b59fe886-c28e-4617-9d9c-920a41291400')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b59fe886-c28e-4617-9d9c-920a41291400 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b59fe886-c28e-4617-9d9c-920a41291400');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "comparison_df = pd.concat([df_lstm, df_lstmatt, df_cnn, df_caml])\n",
        "comparison_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 Miscellaneous"
      ],
      "metadata": {
        "id": "Sigi4WuKeG1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the trained models in this notebook back to the folder \"cs598_project\" in Google drive."
      ],
      "metadata": {
        "id": "X3R3vkOvgRHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp CAML_model drive/MyDrive/cs598_project/CAML_model \n",
        "!cp KSI_CAML_model drive/MyDrive/cs598_project/KSI_CAML_model \n",
        "!cp CNN_model drive/MyDrive/cs598_project/CNN_model \n",
        "!cp KSI_CNN_model drive/MyDrive/cs598_project/KSI_CNN_model\n",
        "!cp RNN_model drive/MyDrive/cs598_project/RNN_model \n",
        "!cp KSI_RNN_model drive/MyDrive/cs598_project/KSI_RNN_model\n",
        "!cp RNNattn_model drive/MyDrive/cs598_project/RNNattn_model \n",
        "!cp KSI_RNNattn_model drive/MyDrive/cs598_project/KSI_RNNattn_model"
      ],
      "metadata": {
        "id": "5X5qTqx_EgaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print out the total running time of the notebook."
      ],
      "metadata": {
        "id": "0qoXT2M3ge5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhjFyQnkSR_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5c1dcc-9de6-40e4-8b59-b931839e530b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total running time of this notebook: 2h 23m 14s\n"
          ]
        }
      ],
      "source": [
        "total_stop = timeit.default_timer()\n",
        "total_duration = str(datetime.timedelta(seconds=round(total_stop - total_start)))\n",
        "total_duration = total_duration.split(\":\")\n",
        "print(f'Total running time of this notebook: {total_duration[0]}h {total_duration[1]}m {total_duration[2]}s')   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8 Reference"
      ],
      "metadata": {
        "id": "PtlBzNla046Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1] Tian Bai and Slobodan Vucetic. 2019. Improving medical code prediction from clinical text via incorporating online knowledge sources. In The World WideWeb Conference, WWW ’19, page 72–82, New York, NY, USA. Association for Computing Machinery.  \n",
        "[2] Alistair E W Johnson, Tom J Pollard, Lu Shen, Li-Wei H Lehman, Mengling Feng, Mohammad Ghassemi,Benjamin Moody, Peter Szolovits, Leo AnthonyCeli, and Roger G Mark. 2016. Mimic-iii,a freely accessible critical care database. Scientific data, 3(1):1–9.  \n",
        "[3] Sepp Hochreiter and Jurgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation,9(8):1735–1780.  \n",
        "[4] Yoon Kim. 2014. Convolutional neural networks for sentence classification.  \n",
        "[5] James Mullenbach, Sarah Wiegreffe, Jon Duke, Jimeng Sun, and Jacob Eisenstein. 2018. Explainable prediction of medical codes from clinical text. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1101–1111, New Orleans, Louisiana. Association for Computational Linguistics.  \n"
      ],
      "metadata": {
        "id": "mPD6Du3n08Dh"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}